{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"AugmentedFlowsterWebscraper.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"GQNG5-secba7","colab_type":"text"},"source":["### Mount Google Drive to runtime"]},{"cell_type":"code","metadata":{"id":"2OUqvCpvcdJq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":157},"executionInfo":{"status":"ok","timestamp":1592786178396,"user_tz":240,"elapsed":28733,"user":{"displayName":"Kevin Dong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrfvovL_K-EjzSiy9r2BbO6ZCCRF-0rJdjiFmRUQ=s64","userId":"03761071086123068512"}},"outputId":"0b43b97e-6411-412e-bedf-04dd50188633"},"source":["from google.colab import drive\n","from os.path import join\n","\n","# Mounting location on runtime for GDrive\n","ROOT = '/content/drive'\n","\n","# Project workspace on GDrive\n","PROJECT_PATH = 'My Drive/Github'\n","\n","# Mount GDrive on the runtime\n","drive.mount(ROOT)\n","\n","# Create the full runtime project path and create a workspace at that location\n","WORKING_PATH = join(ROOT, PROJECT_PATH)\n","!mkdir \"{WORKING_PATH}\" \n","%cd \"{WORKING_PATH}\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","mkdir: cannot create directory ‘/content/drive/My Drive/Github’: File exists\n","/content/drive/My Drive/Github\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Fsiivh5pcdip","colab_type":"text"},"source":["### Install Selenium and chromedriver"]},{"cell_type":"code","metadata":{"id":"cpKk99GhceRw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592786224488,"user_tz":240,"elapsed":38342,"user":{"displayName":"Kevin Dong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrfvovL_K-EjzSiy9r2BbO6ZCCRF-0rJdjiFmRUQ=s64","userId":"03761071086123068512"}},"outputId":"53fc2bea-5696-4829-b659-6f8bc066c961"},"source":["!pip install selenium\n","!apt-get update\n","!apt install chromium-chromedriver\n","!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n","\n","# Add chromedriver location to path\n","import sys\n","sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting selenium\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n","\u001b[K     |████████████████████████████████| 911kB 4.7MB/s \n","\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n","Installing collected packages: selenium\n","Successfully installed selenium-3.141.0\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n","Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n","Get:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n","Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [801 B]\n","Get:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n","Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n","Ign:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n","Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [151 kB]\n","Get:14 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [38.7 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:16 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,840 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,253 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,397 kB]\n","Get:19 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [888 kB]\n","Fetched 5,841 kB in 4s (1,518 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-440\n","Use 'apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n","Suggested packages:\n","  webaccounts-chromium-extension unity-chromium-extension adobe-flashplugin\n","The following NEW packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-chromedriver\n","  chromium-codecs-ffmpeg-extra\n","0 upgraded, 4 newly installed, 0 to remove and 53 not upgraded.\n","Need to get 75.5 MB of archives.\n","After this operation, 256 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 83.0.4103.61-0ubuntu0.18.04.1 [1,119 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 83.0.4103.61-0ubuntu0.18.04.1 [66.7 MB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 83.0.4103.61-0ubuntu0.18.04.1 [3,378 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 83.0.4103.61-0ubuntu0.18.04.1 [4,294 kB]\n","Fetched 75.5 MB in 5s (15.4 MB/s)\n","Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n","(Reading database ... 144328 files and directories currently installed.)\n","Preparing to unpack .../chromium-codecs-ffmpeg-extra_83.0.4103.61-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-codecs-ffmpeg-extra (83.0.4103.61-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser.\n","Preparing to unpack .../chromium-browser_83.0.4103.61-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-browser (83.0.4103.61-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser-l10n.\n","Preparing to unpack .../chromium-browser-l10n_83.0.4103.61-0ubuntu0.18.04.1_all.deb ...\n","Unpacking chromium-browser-l10n (83.0.4103.61-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-chromedriver.\n","Preparing to unpack .../chromium-chromedriver_83.0.4103.61-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-chromedriver (83.0.4103.61-0ubuntu0.18.04.1) ...\n","Setting up chromium-codecs-ffmpeg-extra (83.0.4103.61-0ubuntu0.18.04.1) ...\n","Setting up chromium-browser (83.0.4103.61-0ubuntu0.18.04.1) ...\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n","Setting up chromium-chromedriver (83.0.4103.61-0ubuntu0.18.04.1) ...\n","Setting up chromium-browser-l10n (83.0.4103.61-0ubuntu0.18.04.1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pw-eVkPJcSi9","colab_type":"code","colab":{}},"source":["'''\n","@file       FlowsterWebscraper.py\n","@date       2020/06/09\n","@brief      Class to scrape attributes of interest from all topics on the Flowster Discourse forum\n","'''\n","\n","import time\n","from datetime import datetime\n","import os\n","\n","from bs4 import BeautifulSoup\n","from selenium import webdriver\n","\n","import pandas as pd\n","import json\n","\n","\n","'''\n","@brief  Webscraper that scrapes attributes of interest from all topics on the Flowster Discourse forum\n","'''\n","class FlowsterWebscraper:\n","    driver = None                   # Selenium webdriver object\n","    topicDict = {}                  # Dictionary of all topics and their attributes\n","    topicDataframe = \\\n","        pd.DataFrame(columns=[      # Pandas dataframe of all topic attributes\n","        'Topic Title', \n","        'Category', \n","        'Tags', \n","        'Author', \n","        'Leading Comment', \n","        'Likes',\n","        'Views'])\n","\n","\n","    def __init__(self, webdriverPath):\n","        # Set up webdriver\n","        options = webdriver.ChromeOptions()\n","        options.add_argument('--ignore-certificate-errors')     # Ignore security certificates\n","        options.add_argument('--incognito')                     # Use Chrome in Incognito mode\n","        options.add_argument('--headless')                      # Run in background\n","        options.add_argument('--no-sandbox')\n","        options.add_argument('--disable-dev-shm-usage')\n","        self.driver = webdriver.Chrome( \\\n","            executable_path = webdriverPath, \\\n","            options = options)\n","\n","\n","    '''\n","    @brief      Retrieves a topic title\n","    @param      topicSoup   BeautifulSoup object that contains the topic page HTML\n","    @return     topicName   Topic name\n","    '''\n","    def get_title(self, topicSoup):\n","        topicName = topicSoup.find('a', class_='fancy-title').text\n","\n","        # Remove leading and trailing spaces and newlines\n","        topicName = topicName.replace('\\n', '').strip()\n","        return topicName\n","\n","\n","    '''\n","    @brief      Retrieves a topic's category and tags\n","    @param      topicSoup   BeautifulSoup object that contains the topic page HTML\n","    @return     category    Category that the topic belongs to\n","    @return     tags        List of topic tags\n","    '''\n","    def get_category_and_tags(self, topicSoup):    \n","        topicCategoryDiv = topicSoup.find('div', class_='topic-category ember-view')\n","        tagAnchors = topicCategoryDiv.find_all('span', class_='category-name')\n","\n","        tagList = []\n","        for anchor in tagAnchors:\n","            tagList.append(anchor.text)\n","        \n","        if (len(tagList) == 1):\n","            category = tagList[0]\n","            tags = []\n","            return category, tags\n","        else:\n","            category = tagList[0]\n","            tags = tagList[1:]\n","            return category, tags\n","\n","    \n","    '''\n","    @brief      Retrieves a topic's author and commenters\n","    @param      topicSoup   BeautifulSoup object that contains the topic page HTML\n","    @return     author      Author username\n","    @return     commenters  List of unique commenter usernames\n","    '''\n","    def get_authors(self, topicSoup):\n","        names = topicSoup.find_all(\"div\", class_=\"names trigger-user-card\")\n","        authorList = []\n","        for name in names:\n","            author = name.span.a.text\n","            authorList.append(author)\n","        return author\n","\n","\n","    '''\n","    @brief      Retrieves a topic's comments\n","    @param      topicSoup       BeautifulSoup object that contains the topic page HTML\n","    @return     leadingComment  Leading comment (by the author)\n","    @return     otherComments   List of other comments\n","    '''\n","    def get_comments(self, topicSoup):\n","        postStream = topicSoup.find('div', class_='post-stream')\n","        postDivs = postStream.find_all('div', \\\n","            {'class':['topic-post clearfix regular','topic-post clearfix topic-owner regular']})\n","\n","        comments = []\n","        for i in range(len(postDivs)):\n","            comment = postDivs[i].find('div', class_='cooked').text\n","            comments.append(comment)\n","        return comments\n","\n","\n","    '''\n","    @brief      Retrieves a topic's number of views\n","    @param      topicSoup           BeautifulSoup object that contains the topic page HTML\n","    @return     views.span.text     Number of views as a string\n","    '''\n","    def get_views(self, topicSoup):\n","        views = topicSoup.find('li', class_='secondary views')\n","        if views == None:\n","            return str(0)\n","        return views.span.text\n","        \n","\n","    '''\n","    @brief      Retrieves a topic's number of likes\n","    @param      topicSoup           BeautifulSoup object that contains the topic page HTML\n","    @return     likes.span.text     Number of likes as a string\n","    '''\n","    def get_likes(self, topicSoup):\n","        likes = topicSoup.find('li', class_='secondary likes')\n","        if likes == None:\n","            return str(0)\n","        return likes.span.text\n","    \n","    def get_replies(self, topicSoup):\n","        replies = topicSoup.find('li', class_='replies')\n","        if replies == None:\n","            return str(0)\n","        return replies.span.text\n","    \n","\n","    '''\n","    @brief      Runs the webscraper application and saves the data in both JSON and CSV files\n","    @param      baseURL     Link to the Flowster forum home page\n","    @return     None\n","    '''\n","    def runApplication(self, baseURL):\n","        # Open Chrome web client using Selenium and retrieve page source\n","        self.driver.get(baseURL)\n","        baseHTML = self.driver.page_source\n","\n","        # Get base HTML text and generate soup object\n","        baseSoup = BeautifulSoup(baseHTML, 'html.parser')\n","\n","        # Find all anchor objects that contain category information\n","        categoryAnchors = baseSoup.find_all('a', class_='category-title-link')\n","\n","        # Get hyperlink references and append it to the base URL to get the category page URLs\n","        categoryPageURLs = []\n","        for i in range(len(categoryAnchors)):\n","            href = categoryAnchors[i]['href']\n","            categoryPageURLs.append(baseURL + href)\n","\n","        # 1st for loop to loop through all categories\n","        for categoryURL in categoryPageURLs:\n","            # Access category webpage\n","            self.driver.get(categoryURL)\n","\n","            # Load the entire webage by scrolling to the bottom\n","            lastHeight = self.driver.execute_script(\"return document.body.scrollHeight\")\n","            while (True):\n","                # Scroll to bottom of page\n","                self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n","\n","                # Wait for new page segment to load\n","                time.sleep(0.5)\n","\n","                # Calculate new scroll height and compare with last scroll height\n","                newHeight = self.driver.execute_script(\"return document.body.scrollHeight\")\n","                if newHeight == lastHeight:\n","                    break\n","                lastHeight = newHeight\n","\n","            # Generate category soup object\n","            categoryHTML = self.driver.page_source\n","            categorySoup = BeautifulSoup(categoryHTML, 'html.parser')\n","\n","            # Find all anchor objects that contain topic information\n","            topicAnchors = categorySoup.find_all('a', class_='title raw-link raw-topic-link')\n","\n","            # Get hyperlink references and append it to the base URL to get the topic page URLs\n","            topicPageURLs = []\n","            for i in range(len(topicAnchors)):\n","                href = topicAnchors[i]['href']\n","                topicPageURLs.append(baseURL + href)\n","\n","\n","            # 2nd for loop to loop through all topics in a category\n","            for topicURL in topicPageURLs:\n","                # Get topic HTML text and generate topic soup object\n","                self.driver.get(topicURL)\n","                topicHTML = self.driver.page_source\n","                topicSoup = BeautifulSoup(topicHTML, 'html.parser')\n","\n","                # Scape all topic attributes of interest\n","                topicTitle = self.get_title(topicSoup)\n","                category, tags = self.get_category_and_tags(topicSoup)\n","                author= self.get_authors(topicSoup)\n","                leadingComment= self.get_comments(topicSoup)\n","                numLikes = self.get_likes(topicSoup)\n","                numViews = self.get_views(topicSoup)\n","                replies = self.get_replies(topicSoup)\n","                \n","                counter = 1\n","                for post in leadingComment:\n","\n","                    # Create attribute dictionary for topic\n","                    attributeDict = {\n","                        'Topic Title'       :   topicTitle + str(counter),\n","                        'Category'          :   category,\n","                        'Tags'              :   tags,\n","                        'Author'            :   author,\n","                        'Leading Comment'   :   post,\n","                        'Likes'             :   numLikes,\n","                        'Replies'           :   replies,\n","                        'Views'             :   numViews}\n","\n","                    # Add the new entry to the topic dictionary and Pandas dataframe\n","                    self.topicDict[topicTitle + str(counter)] = attributeDict\n","                    self.topicDataframe = self.topicDataframe.append(attributeDict, ignore_index=True)\n","                    counter += 1\n","                \n","        # Get unique timestamp of the webscraping\n","        timeStamp = datetime.now().strftime('%Y%m%d%H%M%S')\n","\n","        # Save data in JSON and CSV files and store in the save folder as this program\n","        jsonFilename = 'Flowster_Topic_Attributes_' + timeStamp + '.json'\n","        csvFilename = 'Flowster_Topic_Attributes_' + timeStamp + '.csv'\n","\n","        #jsonFileFullPath = os.path.join(os.path.dirname(os.path.realpath(\"__file__\")), jsonFilename)\n","        #csvFileFullPath = os.path.join(os.path.dirname(os.path.realpath(\"__file__\")), csvFilename)\n","\n","        jsonFileFullPath = os.path.join(WORKING_PATH, jsonFilename)\n","        csvFileFullPath = os.path.join(WORKING_PATH, csvFilename)\n","\n","        with open(jsonFileFullPath, 'w') as f:\n","            json.dump(self.topicDict, f)\n","\n","        self.topicDataframe.to_csv(csvFileFullPath)\n","\n","\n","\n","if __name__=='__main__':\n","    # Local path to webdriver\n","    webdriverPath = \"chromedriver\"\n","\n","    # Flowster forum base URL\n","    baseURL = 'https://forum.flowster.app'\n","\n","    # Create FLowster webscraping object\n","    flowsterWebscraper = FlowsterWebscraper(webdriverPath)\n","\n","    # Run webscraping and save data\n","    flowsterWebscraper.runApplication(baseURL)\n"],"execution_count":null,"outputs":[]}]}