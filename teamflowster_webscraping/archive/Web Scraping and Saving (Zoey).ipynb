{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, \\\n",
    "    WebDriverException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flowster forum base URL\n",
    "baseURL = 'https://forum.flowster.app'\n",
    "\n",
    "driver = webdriver.Chrome(executable_path='C:\\chromedriver')\n",
    "\n",
    "# Open Chrome web client using Selenium and retrieve page source\n",
    "driver.get(baseURL)\n",
    "baseHTML = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get base HTML text and generate soup object\n",
    "baseSoup = BeautifulSoup(baseHTML, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://forum.flowster.app/c/human-resources/46\n",
      "https://forum.flowster.app/c/amazon-specific/17\n",
      "https://forum.flowster.app/c/flowster/2\n",
      "https://forum.flowster.app/c/product-sourcing/8\n",
      "https://forum.flowster.app/c/software-tools/26\n",
      "https://forum.flowster.app/c/fulfillment/36\n",
      "https://forum.flowster.app/c/traffic/13\n",
      "https://forum.flowster.app/c/management/32\n",
      "https://forum.flowster.app/c/misc-topics/55\n",
      "https://forum.flowster.app/c/financial-management/21\n",
      "https://forum.flowster.app/c/sales-channels/7\n",
      "https://forum.flowster.app/c/store-website-management/40\n"
     ]
    }
   ],
   "source": [
    "# Find all anchor objects that contain category information\n",
    "categories = baseSoup.find_all('a', class_='category-title-link')\n",
    "\n",
    "categoryPageURLs=[]\n",
    "for category in categories:\n",
    "    categoryPageURL = baseURL + category['href']\n",
    "    categoryPageURLs.append(categoryPageURL)\n",
    "    print(categoryPageURL)\n",
    "    \n",
    "    \n",
    "#print(categoryPageURLs)    \n",
    "    #driver.get(categoryPageURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET ALL LINKS FOR TOPICS ###\n",
    "\n",
    "\n",
    "topicPageURLs=[]\n",
    "\n",
    "for j in range(0, len(categoryPageURLs)):\n",
    "    \n",
    "    categoryPageURL = categoryPageURLs[j]\n",
    "    # Get category HTML text\n",
    "    driver.get(categoryPageURL)\n",
    "\n",
    "\n",
    "    # Load the entire webage by scrolling\n",
    "    lastHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while (True):\n",
    "        # Scroll to bottom of page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait for new page segment to load\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        newHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if newHeight == lastHeight:\n",
    "            break\n",
    "        lastHeight = newHeight\n",
    "\n",
    "\n",
    "    # Generate soup object\n",
    "    categoryHTML = driver.page_source\n",
    "    categorySoup = BeautifulSoup(categoryHTML, 'html.parser')\n",
    "\n",
    "    # Find all anchor objects that contain topic information\n",
    "    topicAnchors = categorySoup.find_all('a', class_='title raw-link raw-topic-link')\n",
    "\n",
    "    # Get hyperlink reference and append it to the base URL to get the topic page URL\n",
    "    for topic in topicAnchors:\n",
    "        topicPageURL = baseURL + topic['href']\n",
    "        topicPageURLs.append(topicPageURL)\n",
    "\n",
    "#print(topicPageURLs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topicPageURLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ALL SCRAPING FUNCTIONS -- RETURN AS DICTIONARIES ###\n",
    "\n",
    "\n",
    "def category(url):\n",
    "    category = tag(url)[0]\n",
    "    return(category)\n",
    "\n",
    "\n",
    "## Leading comment and author (done!)\n",
    "def leading_comment(url):\n",
    "    leading_comment = requests.get(url)\n",
    "    soup2 = BeautifulSoup(leading_comment.text, 'html.parser')\n",
    "    comments = soup2.find_all(\"meta\", property='og:description')\n",
    "    lead='No-Text'\n",
    "    for comment in comments:\n",
    "        lead = comment.get('content')\n",
    "        #print('Leading Commnet: ', lead)\n",
    "\n",
    "    authors = soup2.find_all('span', class_='creator')\n",
    "    author1 = authors[0].getText()\n",
    "    #print('Author1: ', author1.strip())\n",
    "    \n",
    "    ## convert to a dictionary:\n",
    "    d = dict()\n",
    "    d[lead.strip()] = author1.strip()\n",
    "    return d\n",
    "    \n",
    "    \n",
    "    \n",
    "## Other comments (count from 2) and their authors (done!)\n",
    "def other_comment(url):\n",
    "    others = requests.get(url)\n",
    "    soup2 = BeautifulSoup(others.text, 'html.parser')\n",
    "    comments = soup2.findAll('div', {\"class\": \"post\"})\n",
    "    authors = soup2.find_all('span', class_='creator')\n",
    "    \n",
    "    d = dict()\n",
    "    for i in range(1, len(comments)):\n",
    "        comment = comments[i].getText()\n",
    "        author = authors[i].getText()\n",
    "        #print('Comment ' + str(i+1) + ': ' + comment.strip())\n",
    "        #print('Author: ' + str(i+1) + ': ' + author.strip())\n",
    "        #print('---------------------')\n",
    "        \n",
    "        d.update( {comment.strip() : author.strip()} )\n",
    "    return d\n",
    "    \n",
    "  \n",
    "\n",
    "## Tags  (done!)\n",
    "def tag(url):\n",
    "    tags = requests.get(url)\n",
    "    soup2 = BeautifulSoup(tags.text, 'html.parser')\n",
    "    tags = soup2.find_all('span', class_=\"category-name\")\n",
    "    i = 1\n",
    "    tag_list=[]\n",
    "    for g in tags:\n",
    "        tag = g.getText()\n",
    "        #print('Tag: ' + str(i) + ': ' + tag)\n",
    "        i += 1\n",
    "        tag_list.append(tag)\n",
    "        #return(tag)\n",
    "        \n",
    "    return tag_list\n",
    "        \n",
    "\n",
    "        \n",
    "## Topic titles\n",
    "def topic_title(url):\n",
    "    topics = requests.get(url)\n",
    "    soup2 = BeautifulSoup(topics.text, 'html.parser')\n",
    "    topics = soup2.find_all(\"meta\", property=\"og:title\")\n",
    "    for t in topics:\n",
    "        topic = t.get('content')\n",
    "        #print('Topic Title: ', topic)\n",
    "        return(topic)\n",
    "    \n",
    "\n",
    "## Views (doesn't work right)\n",
    "def views(url):\n",
    "    views = requests.get(url)\n",
    "    soup2 = BeautifulSoup(views.text, 'html.parser')\n",
    "    views = soup2.find_all('span')\n",
    "    print(views)\n",
    "    #print('Views: ', view.getText())\n",
    "        \n",
    "        \n",
    "        \n",
    "def dictionary_combination(url):\n",
    "    topic_key = topic_title(url)\n",
    "    category_val = category(url)\n",
    "    tag_val = tag(url)\n",
    "    \n",
    "    leading_dic = leading_comment(url)\n",
    "    other_dic = other_comment(url)\n",
    "    \n",
    "    \n",
    "    \n",
    "    d = dict()\n",
    "    d[topic_key] = [category_val]\n",
    "    d[topic_key].append(tag_val)\n",
    "    d[topic_key].append(leading_dic)\n",
    "    d[topic_key].append(other_dic)\n",
    "    \n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE ALL DICTIONARIES AS A JSON FILE ###\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "final_dict = {}\n",
    "\n",
    "for j in range(0, len(topicPageURLs)):\n",
    "    url = topicPageURLs[j]\n",
    "    \n",
    "    single_dict = dictionary_combination(url)\n",
    "    final_dict.update(single_dict)\n",
    "    #print(j)\n",
    "    \n",
    "#print(final_dict)\n",
    "\n",
    "with open('Flowster_Dict.json', 'w') as f:\n",
    "    json.dump(final_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ALL SCRAPING FUNCTIONS -- RETURN VALUES ###\n",
    "\n",
    "\n",
    "## Category\n",
    "def category2(url):\n",
    "    category = tag(url)[0]\n",
    "    return(category)\n",
    "\n",
    "\n",
    "## Leading comment\n",
    "def leading_comment2(url):\n",
    "    leading_comment = requests.get(url)\n",
    "    soup2 = BeautifulSoup(leading_comment.text, 'html.parser')\n",
    "    comments = soup2.find_all(\"meta\", property='og:description')\n",
    "    for comment in comments:\n",
    "        lead = comment.get('content')\n",
    "        #print('Leading Commnet: ', lead)\n",
    "        return(lead)\n",
    "    \n",
    "    \n",
    "## Other comments (count from 2)\n",
    "def other_comment2(url):\n",
    "    others = requests.get(url)\n",
    "    soup2 = BeautifulSoup(others.text, 'html.parser')\n",
    "    comments = soup2.findAll('div', {\"class\": \"post\"})\n",
    "    i = 2\n",
    "    comment_list=[]\n",
    "    for c in comments:\n",
    "        comment = c.getText()\n",
    "        comment_list.append(comment.strip())\n",
    "        #print('Comment ' + str(i) + ': ' + comment)\n",
    "        i += 1\n",
    "    return(comment_list)\n",
    "\n",
    "    \n",
    "\n",
    "## Tags\n",
    "def tag2(url):\n",
    "    tags = requests.get(url)\n",
    "    soup2 = BeautifulSoup(tags.text, 'html.parser')\n",
    "    tags = soup2.find_all('span', class_=\"category-name\")\n",
    "    i = 1\n",
    "    tag_list=[]\n",
    "    for g in tags:\n",
    "        tag = g.getText()\n",
    "        tag_list.append(tag.strip())\n",
    "        #print('Tag: ' + str(i) + ': ' + tag)\n",
    "        i += 1\n",
    "    return(tag_list)\n",
    "\n",
    "        \n",
    "## Authors\n",
    "def author2(url):\n",
    "    authors = requests.get(url)\n",
    "    soup2 = BeautifulSoup(authors.text, 'html.parser')\n",
    "    authors = soup2.find_all('span', class_='creator')\n",
    "    i = 1\n",
    "    author_list=[]\n",
    "    for a in authors:\n",
    "        author = a.getText()\n",
    "        author_list.append(author.strip())\n",
    "        #print('Author: ' + str(i) + ': ' + author.strip())\n",
    "        i += 1\n",
    "    return(author_list)\n",
    "\n",
    "        \n",
    "## Topic titles\n",
    "def topic_title2(url):\n",
    "    topics = requests.get(url)\n",
    "    soup2 = BeautifulSoup(topics.text, 'html.parser')\n",
    "    topics = soup2.find_all(\"meta\", property=\"og:title\")\n",
    "    for t in topics:\n",
    "        topic = t.get('content')\n",
    "        #print('Topic Title: ', topic)\n",
    "        return(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE AS CSV FILE ###\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "result_df = pd.DataFrame(columns=['Topic Title', 'Category', 'Tags', 'Authors', 'Leading Comment', 'Other Comments'])\n",
    "\n",
    "\n",
    "\n",
    "## get other topic contents and append to dataframe:\n",
    "for j in range(0, len(topicPageURLs)):\n",
    "    url = topicPageURLs[j]\n",
    "    result_df = result_df.append({'Topic Title': topic_title2(url), \n",
    "                                  'Category': category2(url),\n",
    "                                  'Tags': tag2(url), \n",
    "                                  'Authors': author2(url), \n",
    "                                  'Leading Comment': leading_comment2(url), \n",
    "                                  'Other Comments': other_comment2(url)}, ignore_index=True)\n",
    "    #print(j)\n",
    "    \n",
    "#print(result_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('flowster_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Leading Comment</th>\n",
       "      <th>Other Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>About the Human Resources category</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>['Human Resources']</td>\n",
       "      <td>['Kane']</td>\n",
       "      <td>Have questions about Human Resources? This is ...</td>\n",
       "      <td>['Have questions about Human Resources? This i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>VA using PC2 &amp; Revseller</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>['Human Resources']</td>\n",
       "      <td>['twentyfoursevenagent', 'Trent-Admin', 'edsut...</td>\n",
       "      <td>My VA reported not having the Amazon Browser i...</td>\n",
       "      <td>['My VA reported not having the Amazon Browser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Training a VA to find brand contact information</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>['Human Resources']</td>\n",
       "      <td>['Cameron.B', 'Mitch', 'Cameron.B', 'Cameron.B...</td>\n",
       "      <td>Hello everyone, I’m having trouble helping to ...</td>\n",
       "      <td>['Hello everyone, I’m having trouble helping t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Performance reviews for Virtual Assistants?</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>['Human Resources', 'Performance Reviews']</td>\n",
       "      <td>['jims', 'Mitch']</td>\n",
       "      <td>Does anyone do this? I’ve considered it, but w...</td>\n",
       "      <td>['Does anyone do this? I’ve considered it, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Best job sites for virtual assistants?</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>['Human Resources', 'Recruiting']</td>\n",
       "      <td>['Blue', 'jims']</td>\n",
       "      <td>Where does everyone find their VAs? I’ve used ...</td>\n",
       "      <td>['Where does everyone find their VAs? I’ve use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Domestic vs Filipino VAs</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>['Human Resources', 'Outsourcing']</td>\n",
       "      <td>['dast1983', 'LizD', 'EBF', 'dast1983', 'EBF']</td>\n",
       "      <td>Hey everyone -  Need your opinion and experien...</td>\n",
       "      <td>['Hey everyone -\\nNeed your opinion and experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Budgeting for virtual assistants</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>['Human Resources', 'Recruiting']</td>\n",
       "      <td>['MWC1', 'Mitch', 'MWC1', 'Mitch']</td>\n",
       "      <td>Doing budgeting for the upcoming year looking ...</td>\n",
       "      <td>['Doing budgeting for the upcoming year lookin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>What email should be used for VA software use?</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>['Human Resources', 'Managing a Virtual Team']</td>\n",
       "      <td>['WillCompere', 'Mitch', 'WillCompere', 'Mitch']</td>\n",
       "      <td>Does it matter what email you have linked to t...</td>\n",
       "      <td>['Does it matter what email you have linked to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>VA-How Would I Locate a VA to enter listings i...</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>['Human Resources', 'Managing a Virtual Team']</td>\n",
       "      <td>['Bill', 'Laura', 'twentyfoursevenagent', 'PLW...</td>\n",
       "      <td>Good morning to all,  I am new to this forum. ...</td>\n",
       "      <td>['Good morning to all,\\nI am new to this forum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>When to use VAs vs employees?</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>['Human Resources']</td>\n",
       "      <td>['dast1983', 'Mitch', 'dast1983', 'Ben', 'dast...</td>\n",
       "      <td>Hi -  So I’m ready to bring on my second regul...</td>\n",
       "      <td>['Hi -\\nSo I’m ready to bring on my second reg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Topic Title         Category  \\\n",
       "0                 About the Human Resources category  Human Resources   \n",
       "1                           VA using PC2 & Revseller  Human Resources   \n",
       "2    Training a VA to find brand contact information  Human Resources   \n",
       "3        Performance reviews for Virtual Assistants?  Human Resources   \n",
       "4             Best job sites for virtual assistants?  Human Resources   \n",
       "5                           Domestic vs Filipino VAs  Human Resources   \n",
       "6                   Budgeting for virtual assistants  Human Resources   \n",
       "7     What email should be used for VA software use?  Human Resources   \n",
       "8  VA-How Would I Locate a VA to enter listings i...  Human Resources   \n",
       "9                      When to use VAs vs employees?  Human Resources   \n",
       "\n",
       "                                             Tags  \\\n",
       "0                             ['Human Resources']   \n",
       "1                             ['Human Resources']   \n",
       "2                             ['Human Resources']   \n",
       "3      ['Human Resources', 'Performance Reviews']   \n",
       "4               ['Human Resources', 'Recruiting']   \n",
       "5              ['Human Resources', 'Outsourcing']   \n",
       "6               ['Human Resources', 'Recruiting']   \n",
       "7  ['Human Resources', 'Managing a Virtual Team']   \n",
       "8  ['Human Resources', 'Managing a Virtual Team']   \n",
       "9                             ['Human Resources']   \n",
       "\n",
       "                                             Authors  \\\n",
       "0                                           ['Kane']   \n",
       "1  ['twentyfoursevenagent', 'Trent-Admin', 'edsut...   \n",
       "2  ['Cameron.B', 'Mitch', 'Cameron.B', 'Cameron.B...   \n",
       "3                                  ['jims', 'Mitch']   \n",
       "4                                   ['Blue', 'jims']   \n",
       "5     ['dast1983', 'LizD', 'EBF', 'dast1983', 'EBF']   \n",
       "6                 ['MWC1', 'Mitch', 'MWC1', 'Mitch']   \n",
       "7   ['WillCompere', 'Mitch', 'WillCompere', 'Mitch']   \n",
       "8  ['Bill', 'Laura', 'twentyfoursevenagent', 'PLW...   \n",
       "9  ['dast1983', 'Mitch', 'dast1983', 'Ben', 'dast...   \n",
       "\n",
       "                                     Leading Comment  \\\n",
       "0  Have questions about Human Resources? This is ...   \n",
       "1  My VA reported not having the Amazon Browser i...   \n",
       "2  Hello everyone, I’m having trouble helping to ...   \n",
       "3  Does anyone do this? I’ve considered it, but w...   \n",
       "4  Where does everyone find their VAs? I’ve used ...   \n",
       "5  Hey everyone -  Need your opinion and experien...   \n",
       "6  Doing budgeting for the upcoming year looking ...   \n",
       "7  Does it matter what email you have linked to t...   \n",
       "8  Good morning to all,  I am new to this forum. ...   \n",
       "9  Hi -  So I’m ready to bring on my second regul...   \n",
       "\n",
       "                                      Other Comments  \n",
       "0  ['Have questions about Human Resources? This i...  \n",
       "1  ['My VA reported not having the Amazon Browser...  \n",
       "2  ['Hello everyone, I’m having trouble helping t...  \n",
       "3  ['Does anyone do this? I’ve considered it, but...  \n",
       "4  ['Where does everyone find their VAs? I’ve use...  \n",
       "5  ['Hey everyone -\\nNeed your opinion and experi...  \n",
       "6  ['Doing budgeting for the upcoming year lookin...  \n",
       "7  ['Does it matter what email you have linked to...  \n",
       "8  ['Good morning to all,\\nI am new to this forum...  \n",
       "9  ['Hi -\\nSo I’m ready to bring on my second reg...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"flowster_data.csv\", index_col=0) \n",
    "\n",
    "# Preview the first 5 lines of the loaded data \n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda1310509b418348bfb88fedb28bc9a5b8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
