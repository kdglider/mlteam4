{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nnklE-19odma",
    "outputId": "3e7202ad-887a-4cdb-bb6b-6127fbde9c76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T21:37:18.783223Z",
     "start_time": "2020-06-18T21:37:18.631615Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "62Ko9Mogmolz",
    "outputId": "f1f322ae-8094-4b7e-8cf8-dfa2bb69a356"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from html.parser import HTMLParser\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import time\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T21:43:33.209806Z",
     "start_time": "2020-06-18T21:43:33.188860Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "M_uyovYmEzu8"
   },
   "outputs": [],
   "source": [
    "stop_words = list(set(stopwords.words('english')))\n",
    "punct = list(set(string.punctuation))\n",
    "punct.append('“')\n",
    "punct.append('”')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def text_cleaning(text):\n",
    "    # converting HTML character codes to ASCII code\n",
    "    parser = HTMLParser()\n",
    "    text =  parser.unescape(text)\n",
    "    \n",
    "    text = re.sub(r'<[^>]+>','',text) # removing HTML tags\n",
    "    text = re.sub(r'(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)','',text) # removing hash-tags\n",
    "    text = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+','',text) # removing URLs\n",
    "    text = re.sub(r'(?:[\\ufffd]+)','',text) #removing special characters\n",
    "    text = word_tokenize(text)\n",
    "    text = ' '.join(word for word in text if word not in punct) #remove punctuation\n",
    "    text = re.sub('\\n',' ',text) #remove new line\n",
    "    text = re.sub('@','',text) #remove @ sign\n",
    "    text = re.sub('\\'','',text) # remove '\n",
    "    text = text.lower() # lowercase all characters\n",
    "    text = word_tokenize(text) # tonkenize words\n",
    "    text = [i for i in text if not i in stop_words] #remove stop words\n",
    "    #text = [stemmer.stem(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T21:44:50.320970Z",
     "start_time": "2020-06-18T21:44:49.902565Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "V2zx8d44nM_e"
   },
   "outputs": [],
   "source": [
    "#df_1 = pd.read_csv('/content/gdrive/My Drive/Amazon Seller Forum/cleaned_comments.csv') # Gabriel's cleaned comments\n",
    "#df_2 = pd.read_csv('/content/gdrive/My Drive/Amazon Seller Forum/Amazon_Forum_scrape2.csv',encoding= 'unicode_escape') # Wei Huang's comments\n",
    "\n",
    "df_1 = pd.read_csv('cleaned_comments.csv')\n",
    "df_2 = pd.read_csv('Amazon_Forum_scrape2.csv',encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T21:45:34.788534Z",
     "start_time": "2020-06-18T21:44:50.560397Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "RzqCGCZ3tW3m",
    "outputId": "b386f766-b9d2-4aa9-a418-c9777ab84575"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\GJ\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: The unescape method is deprecated and will be removed in 3.5, use html.unescape() instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Cleaning df_1\n",
    "df_1.drop(['Unnamed: 0','Link','Reply Times'],axis=1,inplace=True)\n",
    "df_1['Leading Comment'] = df_1['Leading Comment'].apply(lambda x: ' '.join(word for word in word_tokenize(x) if (word != '“') and (word != '”')))\n",
    "df_1['Title'] = df_1['Title'].apply(lambda x: text_cleaning(x))\n",
    "df_1[\"Publish Time\"] = df_1[\"Publish Time\"].apply(lambda x: pd.to_datetime(x))\n",
    "df_1['Publish hour'] = df_1[\"Publish Time\"].apply(lambda x: x.hour)\n",
    "df_1['Reply Authors'] = df_1['Reply Authors'].apply(lambda x: word_tokenize(x))\n",
    "df_1['Reply Authors'] = df_1['Reply Authors'].apply(lambda x: [word for word in x if word not in punct])\n",
    "df_1['Reply Authors'] = df_1['Reply Authors'].apply(lambda x: [re.sub('\\'','',x[i]) for i in range(len(x))])\n",
    "df_1['Reply Comments'] = df_1['Reply Comments'].apply(lambda x: text_cleaning(x)) \n",
    "df_1['num_Reply_Authors'] = df_1['Reply Authors'].apply(lambda x: len(x))\n",
    "\n",
    "# Cleaning df_2\n",
    "df_2.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df_2.dropna(axis=0,inplace=True)\n",
    "df_2['Topic Title'] = df_2['Topic Title'].apply(lambda x: text_cleaning(x))\n",
    "df_2['Category'] = df_2['Category'].apply(lambda x: x.strip())\n",
    "\n",
    "df_2['Authors'] = df_2['Authors'].apply(lambda x: word_tokenize(x))\n",
    "df_2['Authors'] = df_2['Authors'].apply(lambda x: [word for word in x if word not in punct])\n",
    "df_2['Authors'] = df_2['Authors'].apply(lambda x: [re.sub('\\'','',x[i]) for i in range(len(x))])\n",
    "df_2['Reply Authors'] = df_2['Authors'].apply(lambda x: x[1:])\n",
    "df_2['Authors'] = df_2['Authors'].apply(lambda x: x[0])\n",
    "\n",
    "df_2['Leading Comment'] = df_2['Leading Comment'].apply(lambda x: text_cleaning(x))\n",
    "df_2['Other Comments'] = df_2['Other Comments'].apply(lambda x: text_cleaning(x))\n",
    "df_2.rename(columns={'Topic Title':'Title','Authors':'Post Author','Other Comments':'Reply Comments'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T21:45:35.211715Z",
     "start_time": "2020-06-18T21:45:35.150877Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "2k-yT3xAFvLS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_1[['Title','Category','Post Author','Reply Authors','Leading Comment','Reply Comments']],\n",
    "                df_2[['Title','Category','Post Author','Reply Authors','Leading Comment','Reply Comments']]],axis=0)\n",
    "df['num_Reply_Authors'] = df['Reply Authors'].apply(lambda x: len(x))\n",
    "#df.drop_duplicates(keep='first',inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Zqv4ttQATV_"
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-18T21:47:02.138Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pDzCmro7Achs"
   },
   "outputs": [],
   "source": [
    "df['Leading Comment'] = df['Leading Comment'].apply(lambda x: word_tokenize(x))\n",
    "df['Leading Comment'] = df['Leading Comment'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "df['Leading Comment'] = df['Leading Comment'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "df['Reply Comments'] = df['Reply Comments'].apply(lambda x: word_tokenize(x))\n",
    "df['Reply Comments'] = df['Reply Comments'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "df['Reply Comments'] = df['Reply Comments'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Leading comments</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ohbJCVLkS2gO"
   },
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.7,\n",
    "                             max_features=6000,\n",
    "                             use_idf=True,\n",
    "                             ngram_range=(2,3))\n",
    "\n",
    "vectorized_matrix = vectorizer.fit_transform(df['Leading Comment'])\n",
    "\n",
    "X = pd.DataFrame.sparse.from_spmatrix(vectorized_matrix,\n",
    "                                      columns=vectorizer.get_feature_names())\n",
    "\n",
    "y = df['Category']\n",
    "y = Encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aQcjLxw4LFHo"
   },
   "source": [
    "No Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "_kO2-ebrJ2BA",
    "outputId": "37ce4b6c-1b24-4ccc-9f95-bed5d141e57e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77       429\n",
      "           1       0.63      0.26      0.37        93\n",
      "           2       0.67      0.31      0.42       101\n",
      "           3       0.62      0.46      0.53       180\n",
      "           4       0.72      0.50      0.59        98\n",
      "           5       0.68      0.56      0.62       461\n",
      "           6       0.48      0.11      0.18       178\n",
      "           7       0.73      0.28      0.40       176\n",
      "           8       0.11      0.04      0.06        27\n",
      "           9       0.83      0.45      0.59        64\n",
      "          10       0.39      0.76      0.52       623\n",
      "\n",
      "    accuracy                           0.55      2430\n",
      "   macro avg       0.61      0.41      0.46      2430\n",
      "weighted avg       0.61      0.55      0.54      2430\n",
      "\n",
      "model run time: 1297.55 s\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training and testing\n",
    "X_train,X_test,y_train,y_test = train_test_split(X.values,y,\n",
    "                                                 test_size=0.3,\n",
    "                                                 random_state=123)\n",
    "# Initiate model\n",
    "clf = xgb.XGBClassifier(max_depth = 10, \n",
    "                        n_estimators = 150, \n",
    "                        n_jobs = 3, \n",
    "                        colsample_bytree = 0.5,\n",
    "                        gamma = 0.01,\n",
    "                        objective='multi:softmax')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "run_time = end_time - start_time\n",
    "\n",
    "# Display result\n",
    "result = classification_report(y_test,y_pred)\n",
    "print(result)\n",
    "\n",
    "print('model run time: {} s'.format(np.round(run_time,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2xxh9d_K-IN"
   },
   "source": [
    "Resampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "Z8D4aVyFA-Ho",
    "outputId": "adb11056-59ff-479f-ee41-7a6e7a20a97d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.43      0.42        23\n",
      "           1       0.39      0.36      0.37        25\n",
      "           2       0.36      0.33      0.35        27\n",
      "           3       0.50      0.28      0.36        36\n",
      "           4       0.50      0.42      0.46        26\n",
      "           5       0.24      0.35      0.29        20\n",
      "           6       0.16      0.46      0.24        24\n",
      "           7       0.43      0.33      0.38        27\n",
      "           8       0.29      0.17      0.21        24\n",
      "           9       0.62      0.50      0.56        30\n",
      "          10       0.22      0.16      0.18        32\n",
      "\n",
      "    accuracy                           0.34       294\n",
      "   macro avg       0.37      0.34      0.35       294\n",
      "weighted avg       0.38      0.34      0.35       294\n",
      "\n",
      "model run time: 173.55 s\n"
     ]
    }
   ],
   "source": [
    "rus = RandomUnderSampler()\n",
    "X_resampled,y_resampled = rus.fit_resample(X,y)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_resampled,y_resampled,\n",
    "                                                 test_size=0.3,\n",
    "                                                 random_state=123)\n",
    "\n",
    "clf = xgb.XGBClassifier(max_depth = 10, \n",
    "                        n_estimators = 150, \n",
    "                        n_jobs = 3, \n",
    "                        colsample_bytree = 0.5,\n",
    "                        gamma = 0.01,\n",
    "                        objective='multi:softmax')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "run_time = end_time - start_time\n",
    "\n",
    "result = classification_report(y_test,y_pred)\n",
    "print(result)\n",
    "\n",
    "print('model run time: {} s'.format(np.round(run_time,2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> all comments </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T21:50:09.145727Z",
     "start_time": "2020-06-18T21:50:09.073920Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = df['Leading Comment'] + df['Reply Comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T23:38:48.013861Z",
     "start_time": "2020-06-18T23:38:08.702774Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "onD2q_2MMQfl"
   },
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.7,\n",
    "                             max_features=6000,\n",
    "                             use_idf=True,\n",
    "                             ngram_range=(2,3))\n",
    "\n",
    "vectorized_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "X = pd.DataFrame.sparse.from_spmatrix(vectorized_matrix,\n",
    "                                      columns=vectorizer.get_feature_names())\n",
    "\n",
    "y = df['Category']\n",
    "y = Encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T01:14:54.246576Z",
     "start_time": "2020-06-19T00:36:21.802324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost classifier Benchmark\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86       429\n",
      "           1       0.67      0.35      0.46        93\n",
      "           2       0.73      0.48      0.57       101\n",
      "           3       0.64      0.48      0.55       180\n",
      "           4       0.72      0.54      0.62        98\n",
      "           5       0.73      0.61      0.66       461\n",
      "           6       0.59      0.30      0.40       178\n",
      "           7       0.79      0.56      0.66       176\n",
      "           8       0.00      0.00      0.00        27\n",
      "           9       0.90      0.69      0.78        64\n",
      "          10       0.47      0.76      0.58       623\n",
      "\n",
      "    accuracy                           0.64      2430\n",
      "   macro avg       0.64      0.51      0.56      2430\n",
      "weighted avg       0.66      0.64      0.63      2430\n",
      "\n",
      "model run time: 2312.28 s\n"
     ]
    }
   ],
   "source": [
    "print('XGBoost classifier Benchmark')\n",
    "clf = xgb.XGBClassifier(objective='multi:softmax')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "run_time = end_time - start_time\n",
    "\n",
    "# Display result\n",
    "result = classification_report(y_test,y_pred)\n",
    "print(result)\n",
    "\n",
    "print('model run time: {} s'.format(np.round(run_time,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T00:31:17.413254Z",
     "start_time": "2020-06-18T23:40:44.307867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       429\n",
      "           1       0.59      0.39      0.47        93\n",
      "           2       0.61      0.43      0.50       101\n",
      "           3       0.63      0.51      0.56       180\n",
      "           4       0.68      0.52      0.59        98\n",
      "           5       0.69      0.64      0.66       461\n",
      "           6       0.48      0.33      0.39       178\n",
      "           7       0.78      0.56      0.65       176\n",
      "           8       0.14      0.04      0.06        27\n",
      "           9       0.88      0.66      0.75        64\n",
      "          10       0.48      0.70      0.57       623\n",
      "\n",
      "    accuracy                           0.63      2430\n",
      "   macro avg       0.62      0.51      0.55      2430\n",
      "weighted avg       0.64      0.63      0.62      2430\n",
      "\n",
      "model run time: 3027.77 s\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X.values,y,\n",
    "                                                 test_size=0.3,\n",
    "                                                 random_state=123)\n",
    "# Initiate model\n",
    "clf = xgb.XGBClassifier(max_depth = 10, \n",
    "                        n_estimators = 150, \n",
    "                        n_jobs = 3, \n",
    "                        colsample_bytree = 0.5,\n",
    "                        gamma = 0.01,\n",
    "                        objective='multi:softmax')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "run_time = end_time - start_time\n",
    "\n",
    "# Display result\n",
    "result = classification_report(y_test,y_pred)\n",
    "print(result)\n",
    "\n",
    "print('model run time: {} s'.format(np.round(run_time,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "xWrqzPQgU5o2",
    "TLh0x6q8BMRK"
   ],
   "name": "Team4_Amazon_Exploratory_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
