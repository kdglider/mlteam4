{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XLNet_GJ.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pl1jAjg5CJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "ec71c0a9-2d4c-49a9-88b3-0636c972237b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB0VMrmZkDct",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "2ae43160-dc7e-48cc-8fd2-be8d13385fc9"
      },
      "source": [
        "# If running type is GPU, run this cell\n",
        "\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "\n",
        "printm()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=53d496ab661082ccf843c37c6ef1a5fefcad3e108f9396a6d927c47b6e480bd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 161.3 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOdDEIK9d4W1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If run type is TPU, run this cell \n",
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n",
        "\n",
        "try:\n",
        "  # imports the torch_xla package\n",
        "  import torch_xla\n",
        "  import torch_xla.core.xla_model as xm\n",
        "\n",
        "  device = xm.xla_device()\n",
        "\n",
        "except:\n",
        "  VERSION = \"20200325\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "  !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "  !python pytorch-xla-env-setup.py --version $VERSION\n",
        "\n",
        "  # imports pytorch\n",
        "  import torch\n",
        "\n",
        "  # imports the torch_xla package\n",
        "  import torch_xla\n",
        "  import torch_xla.core.xla_model as xm\n",
        "\n",
        "  device = xm.xla_device()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLPPEaiL6NOf",
        "colab_type": "text"
      },
      "source": [
        "Python library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CIkr-Lq5bYV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0408b610-0953-4d93-870e-ea1a285c2e17"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "from html.parser import HTMLParser\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "try:\n",
        "  import transformers as ppb\n",
        "except:\n",
        "  !pip install transformers\n",
        "  import transformers as ppb\n",
        "\n",
        "from transformers import AdamW, BertConfig, get_linear_schedule_with_warmup"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mospiZM4LRjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ebd20723-d78f-46a9-8781-6cfd65faf5ec"
      },
      "source": [
        "# If running on GPU, run this cell to enable cuda\n",
        "if torch.cuda.is_available():    \n",
        "  \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRxQICFkcHcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_cleaning(text):\n",
        "    # converting HTML character codes to ASCII code\n",
        "    parser = HTMLParser()\n",
        "    text = parser.unescape(text)\n",
        "\n",
        "    text = re.sub(r'<[^>]+>', '', text)  # removing HTML tags\n",
        "    text = re.sub(r'(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)', '', text)  # removing hash-tags\n",
        "    text = re.sub('\\n', ' ', text)  # remove new line\n",
        "    text = re.sub('@', '', text)  # remove @ sign\n",
        "    #text = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', '',text)  # removing URLs\n",
        "    text = re.sub(r'(?:[\\ufffd]+)', '', text)  # removing special characters\n",
        "    text = text.lower()\n",
        "\n",
        "    return text"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_dlz6sBVIp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "    # display the elapsed time when loading the data into the BERT model\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JD4_tcwtsKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(pred, true):\n",
        "    pred_flat = np.argmax(pred, axis=1).flatten()\n",
        "    true_flat = true.flatten()\n",
        "    return np.sum(pred_flat == true_flat) / len(true_flat)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46005IXE8-Ya",
        "colab_type": "text"
      },
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsTZwBST6rd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/gdrive/My Drive/Amazon Seller Forum/final_merged_data.csv')\n",
        "df.drop('Unnamed: 0',axis=1,inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hD5Y4fV61hp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "5f94f8fc-3997-41fc-c9be-b10b800a2015"
      },
      "source": [
        "print(df.isna().sum())\n",
        "print('')\n",
        "\n",
        "nan_row = np.where(df.isna())[0][0]\n",
        "print(df.iloc[nan_row,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title              0\n",
            "Post Author        0\n",
            "Leading Comment    1\n",
            "Reply Comments     0\n",
            "Category           0\n",
            "Forum              0\n",
            "dtype: int64\n",
            "\n",
            "Title              Israel Cohen’s Success Story1\n",
            "Post Author                          Trent-Admin\n",
            "Leading Comment                              NaN\n",
            "Reply Comments                                []\n",
            "Category                             Misc Topics\n",
            "Forum                                   Flowster\n",
            "Name: 8832, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9sjJiTnk_1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dropna(axis=0,subset=['Leading Comment'],inplace = True)\n",
        "df.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve8t228ogSoo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "3f4cddb7-7873-48d7-e886-ac0db9c4ae0c"
      },
      "source": [
        "df['Category'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Selling on Amazon                                     2100\n",
              "Account Health                                        1549\n",
              "Fulfillment By Amazon                                 1500\n",
              "Global Selling                                         600\n",
              "Amazon Pay                                             600\n",
              "Groups                                                 494\n",
              "Site Feedback                                          300\n",
              "Amazon Marketplace Web Service (MWS)                   300\n",
              "US Announcements                                       300\n",
              "Amazon Sponsored Products                              300\n",
              "Amazon Custom                                          274\n",
              "Login With Amazon                                      199\n",
              "Health,Safety,Sustainability,Security & Compliance      63\n",
              "Flowster-specific                                       59\n",
              "Amazon Specific                                         53\n",
              "Product Sourcing                                        53\n",
              "Human Resources                                         21\n",
              "Fulfillment                                             17\n",
              "Management                                              15\n",
              "Software & Tools                                        14\n",
              "Misc Topics                                             10\n",
              "Traffic Sources                                          8\n",
              "Financial Management                                     8\n",
              "eCommerce Marketplaces                                   2\n",
              "Store & Website Management                               1\n",
              "Name: Category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CTP01VCKT8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df['num_sent'] = df['Leading Comment'].apply(lambda x: len(sent_tokenize(x)))\n",
        "#df['num_word']= df['Leading Comment'].apply(lambda x: len(word_tokenize(x)))\n",
        "#df['num_capword_title'] = df['Title'].apply(lambda x: sum(word[0].isupper() for word in word_tokenize(x)))\n",
        "\n",
        "#row_drop_idx = df[df['Category'] == 'Store & Website Management'].index[0]\n",
        "\n",
        "#df.drop(df.index[row_drop_idx],inplace=True)\n",
        "#df.reset_index(drop=True,inplace=True)\n",
        "\n",
        "#row_drop_idx = df[df['Category'] == 'eCommerce Marketplaces'].index[0]\n",
        "#df.drop(df.index[row_drop_idx],inplace=True)\n",
        "#df.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8KBi3rfbTBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comments = df['Leading Comment'].apply(lambda x:text_cleaning(x))\n",
        "#df['corpus'] = df['Title']+\" \"+ df['Leading Comment']\n",
        "#df['corpus'] = df['corpus'].apply(lambda x:text_cleaning(x))\n",
        "#corpus = df['corpus']\n",
        "\n",
        "#df_amazon = df[df['Forum']=='Amazon']\n",
        "#comments = df_amazon['Leading Comment'].apply(lambda x:text_cleaning(x))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B90MRkL8869b",
        "colab_type": "text"
      },
      "source": [
        "Load Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf2hlrox63ES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3e333eca-4c2d-470c-c6c7-73fc0befbd21"
      },
      "source": [
        "from transformers import XLNetForSequenceClassification, XLNetTokenizer\n",
        "\n",
        "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
        "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\",\n",
        "                                                       num_labels=df['Category'].nunique())\n",
        "\n",
        "\n",
        "# Load pretrained DistilBert model/tokenizer\n",
        "\n",
        "#tokenizer = ppb.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "#model = ppb.DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',num_labels=df['Category'].nunique())\n",
        "model.to(device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
            "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForSequenceClassification(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (6): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (7): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (8): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (9): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (10): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (11): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (sequence_summary): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (first_dropout): Identity()\n",
              "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (logits_proj): Linear(in_features=768, out_features=25, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6CJFDQB9z4v",
        "colab_type": "text"
      },
      "source": [
        "tokenize leading comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2HQvrIX9u2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_encoder = LabelEncoder()\n",
        "inputs = []\n",
        "attention_masks = []\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "    #   1. Tokenize the sentence.\n",
        "    #   2. Prepend the `[CLS]` token to the start.\n",
        "    #   3. Append the `[SEP]` token to the end.\n",
        "    #   4. Map tokens to their IDs.\n",
        "    #   5. Pad or truncate the sentence to `max_length`\n",
        "    #   6. Create attention masks for [PAD] tokens.\n",
        "\n",
        "for comment in comments:\n",
        "#for comment in corpus:\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        comment,                      \n",
        "                        add_special_tokens = True, \n",
        "                        truncation=True,\n",
        "                        max_length = 512,           \n",
        "                        pad_to_max_length = True,\n",
        "                        return_overflowing_tokens=True,\n",
        "                        stride=70,\n",
        "                        return_attention_mask = True,  \n",
        "                        return_tensors = 'pt',     \n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    inputs.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors and load them to GPU/TPU\n",
        "inputs = torch.cat(inputs, dim=0)#.to(device)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)#.to(device)\n",
        "\n",
        "# Encoding the labels and convert them to tensor \n",
        "labels = label_encoder.fit_transform(df['Category'])\n",
        "labels = torch.tensor(labels)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twavs2Iwbpsf",
        "colab_type": "text"
      },
      "source": [
        "Prepare training dataset and validating dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akYLG2DmboLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 8\n",
        "\n",
        "train_size = int(len(comments)*0.7)\n",
        "val_size = int(len(comments)*0.1)\n",
        "test_size = len(comments) - train_size - val_size\n",
        "\n",
        "dataset = TensorDataset(inputs,attention_masks,labels)\n",
        "\n",
        "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, sampler = RandomSampler(train_set), batch_size = batch_size)\n",
        "\n",
        "val_loader = DataLoader(val_set, sampler = SequentialSampler(val_set), batch_size = batch_size)\n",
        "\n",
        "test_loader = DataLoader(test_set, sampler = SequentialSampler(test_set), batch_size = batch_size)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozQz6Zzih1o4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, \n",
        "                  eps = 1e-8)\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps = [number of batches]*[number of epochs]. \n",
        "total_steps = len(train_loader)*epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3CM8rGPfPHc",
        "colab_type": "text"
      },
      "source": [
        "Training Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFiZuDZXe79f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb3bb5b7-47c3-4db9-a593-edc2675400cf"
      },
      "source": [
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_log = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  time_start = time.time()\n",
        "  total_train_loss = 0\n",
        "\n",
        "  print('begin training')\n",
        "  print('')\n",
        "\n",
        "  model.train()\n",
        "  \n",
        "  for step, batch in enumerate(train_loader):\n",
        "    if step % 10 == 0 and not step == 0:\n",
        "      elapsed = format_time(time.time()-time_start)\n",
        "      print('Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_loader), elapsed))\n",
        "    \n",
        "    b_inputs = batch[0].to(device)\n",
        "    b_attention_masks = batch[1].to(device)\n",
        "    b_label = batch[2].to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "    loss, logit = model(b_inputs,attention_mask=b_attention_masks, labels = b_label)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    total_train_loss += loss.item()\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    \n",
        "\n",
        "  avg_train_loss = total_train_loss/len(train_loader)\n",
        "  training_time = format_time(time.time() - time_start)\n",
        "  print('')\n",
        "  print('Average training loss: {0:.2f}'.format(avg_train_loss))\n",
        "  print('Training epcoh time: {:}'.format(training_time))\n",
        "  \n",
        "  print('')\n",
        "  print('begin validation')\n",
        "\n",
        "  time_start = time.time()\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  total_eval_acc = 0\n",
        "  total_eval_loss = 0\n",
        "  nb_eval_steps = 0\n",
        "\n",
        "  for batch in val_loader:\n",
        "    b_inputs = batch[0].cuda()\n",
        "    b_attention_masks = batch[1].cuda()\n",
        "    b_label = batch[2].cuda() \n",
        "\n",
        "    with torch.no_grad():\n",
        "      (loss, logits) = model(b_inputs,attention_mask=b_attention_masks, labels = b_label)\n",
        "\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label = b_label.to('cpu').numpy()\n",
        "\n",
        "    total_eval_acc += get_accuracy(logits, label)\n",
        "  \n",
        "  avg_val_accuracy = total_eval_acc/len(val_loader)\n",
        "  print(\"Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "  avg_val_loss = total_eval_loss/len(val_loader)\n",
        "\n",
        "  validation_time = format_time(time.time() - time_start)\n",
        "  \n",
        "  print(\"Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "  print(\"Validation time: {:}\".format(validation_time))\n",
        "\n",
        "  training_log.append(\n",
        "        {\n",
        "            'epoch': epoch+1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "  \n",
        "print('training complete')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin training\n",
            "\n",
            "Batch    10  of    774.    Elapsed: 0:00:26.\n",
            "Batch    20  of    774.    Elapsed: 0:00:52.\n",
            "Batch    30  of    774.    Elapsed: 0:01:19.\n",
            "Batch    40  of    774.    Elapsed: 0:01:45.\n",
            "Batch    50  of    774.    Elapsed: 0:02:11.\n",
            "Batch    60  of    774.    Elapsed: 0:02:38.\n",
            "Batch    70  of    774.    Elapsed: 0:03:04.\n",
            "Batch    80  of    774.    Elapsed: 0:03:30.\n",
            "Batch    90  of    774.    Elapsed: 0:03:56.\n",
            "Batch   100  of    774.    Elapsed: 0:04:23.\n",
            "Batch   110  of    774.    Elapsed: 0:04:49.\n",
            "Batch   120  of    774.    Elapsed: 0:05:15.\n",
            "Batch   130  of    774.    Elapsed: 0:05:42.\n",
            "Batch   140  of    774.    Elapsed: 0:06:08.\n",
            "Batch   150  of    774.    Elapsed: 0:06:34.\n",
            "Batch   160  of    774.    Elapsed: 0:07:01.\n",
            "Batch   170  of    774.    Elapsed: 0:07:27.\n",
            "Batch   180  of    774.    Elapsed: 0:07:53.\n",
            "Batch   190  of    774.    Elapsed: 0:08:19.\n",
            "Batch   200  of    774.    Elapsed: 0:08:46.\n",
            "Batch   210  of    774.    Elapsed: 0:09:12.\n",
            "Batch   220  of    774.    Elapsed: 0:09:38.\n",
            "Batch   230  of    774.    Elapsed: 0:10:05.\n",
            "Batch   240  of    774.    Elapsed: 0:10:31.\n",
            "Batch   250  of    774.    Elapsed: 0:10:57.\n",
            "Batch   260  of    774.    Elapsed: 0:11:24.\n",
            "Batch   270  of    774.    Elapsed: 0:11:50.\n",
            "Batch   280  of    774.    Elapsed: 0:12:16.\n",
            "Batch   290  of    774.    Elapsed: 0:12:42.\n",
            "Batch   300  of    774.    Elapsed: 0:13:09.\n",
            "Batch   310  of    774.    Elapsed: 0:13:35.\n",
            "Batch   320  of    774.    Elapsed: 0:14:01.\n",
            "Batch   330  of    774.    Elapsed: 0:14:27.\n",
            "Batch   340  of    774.    Elapsed: 0:14:54.\n",
            "Batch   350  of    774.    Elapsed: 0:15:20.\n",
            "Batch   360  of    774.    Elapsed: 0:15:46.\n",
            "Batch   370  of    774.    Elapsed: 0:16:13.\n",
            "Batch   380  of    774.    Elapsed: 0:16:39.\n",
            "Batch   390  of    774.    Elapsed: 0:17:05.\n",
            "Batch   400  of    774.    Elapsed: 0:17:31.\n",
            "Batch   410  of    774.    Elapsed: 0:17:58.\n",
            "Batch   420  of    774.    Elapsed: 0:18:24.\n",
            "Batch   430  of    774.    Elapsed: 0:18:50.\n",
            "Batch   440  of    774.    Elapsed: 0:19:17.\n",
            "Batch   450  of    774.    Elapsed: 0:19:43.\n",
            "Batch   460  of    774.    Elapsed: 0:20:09.\n",
            "Batch   470  of    774.    Elapsed: 0:20:35.\n",
            "Batch   480  of    774.    Elapsed: 0:21:02.\n",
            "Batch   490  of    774.    Elapsed: 0:21:28.\n",
            "Batch   500  of    774.    Elapsed: 0:21:54.\n",
            "Batch   510  of    774.    Elapsed: 0:22:21.\n",
            "Batch   520  of    774.    Elapsed: 0:22:47.\n",
            "Batch   530  of    774.    Elapsed: 0:23:13.\n",
            "Batch   540  of    774.    Elapsed: 0:23:39.\n",
            "Batch   550  of    774.    Elapsed: 0:24:06.\n",
            "Batch   560  of    774.    Elapsed: 0:24:32.\n",
            "Batch   570  of    774.    Elapsed: 0:24:58.\n",
            "Batch   580  of    774.    Elapsed: 0:25:24.\n",
            "Batch   590  of    774.    Elapsed: 0:25:51.\n",
            "Batch   600  of    774.    Elapsed: 0:26:17.\n",
            "Batch   610  of    774.    Elapsed: 0:26:43.\n",
            "Batch   620  of    774.    Elapsed: 0:27:09.\n",
            "Batch   630  of    774.    Elapsed: 0:27:36.\n",
            "Batch   640  of    774.    Elapsed: 0:28:02.\n",
            "Batch   650  of    774.    Elapsed: 0:28:28.\n",
            "Batch   660  of    774.    Elapsed: 0:28:54.\n",
            "Batch   670  of    774.    Elapsed: 0:29:21.\n",
            "Batch   680  of    774.    Elapsed: 0:29:47.\n",
            "Batch   690  of    774.    Elapsed: 0:30:13.\n",
            "Batch   700  of    774.    Elapsed: 0:30:40.\n",
            "Batch   710  of    774.    Elapsed: 0:31:06.\n",
            "Batch   720  of    774.    Elapsed: 0:31:32.\n",
            "Batch   730  of    774.    Elapsed: 0:31:59.\n",
            "Batch   740  of    774.    Elapsed: 0:32:25.\n",
            "Batch   750  of    774.    Elapsed: 0:32:51.\n",
            "Batch   760  of    774.    Elapsed: 0:33:18.\n",
            "Batch   770  of    774.    Elapsed: 0:33:44.\n",
            "\n",
            "Average training loss: 1.71\n",
            "Training epcoh time: 0:33:53\n",
            "\n",
            "begin validation\n",
            "Accuracy: 0.64\n",
            "Validation Loss: 1.26\n",
            "Validation time: 0:02:17\n",
            "begin training\n",
            "\n",
            "Batch    10  of    774.    Elapsed: 0:00:26.\n",
            "Batch    20  of    774.    Elapsed: 0:00:53.\n",
            "Batch    30  of    774.    Elapsed: 0:01:19.\n",
            "Batch    40  of    774.    Elapsed: 0:01:45.\n",
            "Batch    50  of    774.    Elapsed: 0:02:11.\n",
            "Batch    60  of    774.    Elapsed: 0:02:38.\n",
            "Batch    70  of    774.    Elapsed: 0:03:04.\n",
            "Batch    80  of    774.    Elapsed: 0:03:30.\n",
            "Batch    90  of    774.    Elapsed: 0:03:56.\n",
            "Batch   100  of    774.    Elapsed: 0:04:23.\n",
            "Batch   110  of    774.    Elapsed: 0:04:49.\n",
            "Batch   120  of    774.    Elapsed: 0:05:15.\n",
            "Batch   130  of    774.    Elapsed: 0:05:42.\n",
            "Batch   140  of    774.    Elapsed: 0:06:08.\n",
            "Batch   150  of    774.    Elapsed: 0:06:34.\n",
            "Batch   160  of    774.    Elapsed: 0:07:00.\n",
            "Batch   170  of    774.    Elapsed: 0:07:27.\n",
            "Batch   180  of    774.    Elapsed: 0:07:53.\n",
            "Batch   190  of    774.    Elapsed: 0:08:19.\n",
            "Batch   200  of    774.    Elapsed: 0:08:45.\n",
            "Batch   210  of    774.    Elapsed: 0:09:12.\n",
            "Batch   220  of    774.    Elapsed: 0:09:38.\n",
            "Batch   230  of    774.    Elapsed: 0:10:04.\n",
            "Batch   240  of    774.    Elapsed: 0:10:30.\n",
            "Batch   250  of    774.    Elapsed: 0:10:57.\n",
            "Batch   260  of    774.    Elapsed: 0:11:23.\n",
            "Batch   270  of    774.    Elapsed: 0:11:49.\n",
            "Batch   280  of    774.    Elapsed: 0:12:16.\n",
            "Batch   290  of    774.    Elapsed: 0:12:42.\n",
            "Batch   300  of    774.    Elapsed: 0:13:08.\n",
            "Batch   310  of    774.    Elapsed: 0:13:34.\n",
            "Batch   320  of    774.    Elapsed: 0:14:01.\n",
            "Batch   330  of    774.    Elapsed: 0:14:27.\n",
            "Batch   340  of    774.    Elapsed: 0:14:53.\n",
            "Batch   350  of    774.    Elapsed: 0:15:20.\n",
            "Batch   360  of    774.    Elapsed: 0:15:46.\n",
            "Batch   370  of    774.    Elapsed: 0:16:12.\n",
            "Batch   380  of    774.    Elapsed: 0:16:38.\n",
            "Batch   390  of    774.    Elapsed: 0:17:05.\n",
            "Batch   400  of    774.    Elapsed: 0:17:31.\n",
            "Batch   410  of    774.    Elapsed: 0:17:57.\n",
            "Batch   420  of    774.    Elapsed: 0:18:24.\n",
            "Batch   430  of    774.    Elapsed: 0:18:50.\n",
            "Batch   440  of    774.    Elapsed: 0:19:16.\n",
            "Batch   450  of    774.    Elapsed: 0:19:42.\n",
            "Batch   460  of    774.    Elapsed: 0:20:09.\n",
            "Batch   470  of    774.    Elapsed: 0:20:35.\n",
            "Batch   480  of    774.    Elapsed: 0:21:01.\n",
            "Batch   490  of    774.    Elapsed: 0:21:27.\n",
            "Batch   500  of    774.    Elapsed: 0:21:54.\n",
            "Batch   510  of    774.    Elapsed: 0:22:20.\n",
            "Batch   520  of    774.    Elapsed: 0:22:46.\n",
            "Batch   530  of    774.    Elapsed: 0:23:12.\n",
            "Batch   540  of    774.    Elapsed: 0:23:38.\n",
            "Batch   550  of    774.    Elapsed: 0:24:05.\n",
            "Batch   560  of    774.    Elapsed: 0:24:31.\n",
            "Batch   570  of    774.    Elapsed: 0:24:57.\n",
            "Batch   580  of    774.    Elapsed: 0:25:23.\n",
            "Batch   590  of    774.    Elapsed: 0:25:49.\n",
            "Batch   600  of    774.    Elapsed: 0:26:16.\n",
            "Batch   610  of    774.    Elapsed: 0:26:42.\n",
            "Batch   620  of    774.    Elapsed: 0:27:08.\n",
            "Batch   630  of    774.    Elapsed: 0:27:34.\n",
            "Batch   640  of    774.    Elapsed: 0:28:00.\n",
            "Batch   650  of    774.    Elapsed: 0:28:27.\n",
            "Batch   660  of    774.    Elapsed: 0:28:53.\n",
            "Batch   670  of    774.    Elapsed: 0:29:19.\n",
            "Batch   680  of    774.    Elapsed: 0:29:45.\n",
            "Batch   690  of    774.    Elapsed: 0:30:11.\n",
            "Batch   700  of    774.    Elapsed: 0:30:38.\n",
            "Batch   710  of    774.    Elapsed: 0:31:04.\n",
            "Batch   720  of    774.    Elapsed: 0:31:30.\n",
            "Batch   730  of    774.    Elapsed: 0:31:56.\n",
            "Batch   740  of    774.    Elapsed: 0:32:23.\n",
            "Batch   750  of    774.    Elapsed: 0:32:49.\n",
            "Batch   760  of    774.    Elapsed: 0:33:15.\n",
            "Batch   770  of    774.    Elapsed: 0:33:41.\n",
            "\n",
            "Average training loss: 1.07\n",
            "Training epcoh time: 0:33:50\n",
            "\n",
            "begin validation\n",
            "Accuracy: 0.67\n",
            "Validation Loss: 1.11\n",
            "Validation time: 0:02:16\n",
            "begin training\n",
            "\n",
            "Batch    10  of    774.    Elapsed: 0:00:26.\n",
            "Batch    20  of    774.    Elapsed: 0:00:52.\n",
            "Batch    30  of    774.    Elapsed: 0:01:19.\n",
            "Batch    40  of    774.    Elapsed: 0:01:45.\n",
            "Batch    50  of    774.    Elapsed: 0:02:11.\n",
            "Batch    60  of    774.    Elapsed: 0:02:37.\n",
            "Batch    70  of    774.    Elapsed: 0:03:03.\n",
            "Batch    80  of    774.    Elapsed: 0:03:29.\n",
            "Batch    90  of    774.    Elapsed: 0:03:56.\n",
            "Batch   100  of    774.    Elapsed: 0:04:22.\n",
            "Batch   110  of    774.    Elapsed: 0:04:48.\n",
            "Batch   120  of    774.    Elapsed: 0:05:14.\n",
            "Batch   130  of    774.    Elapsed: 0:05:40.\n",
            "Batch   140  of    774.    Elapsed: 0:06:07.\n",
            "Batch   150  of    774.    Elapsed: 0:06:33.\n",
            "Batch   160  of    774.    Elapsed: 0:06:59.\n",
            "Batch   170  of    774.    Elapsed: 0:07:25.\n",
            "Batch   180  of    774.    Elapsed: 0:07:52.\n",
            "Batch   190  of    774.    Elapsed: 0:08:18.\n",
            "Batch   200  of    774.    Elapsed: 0:08:44.\n",
            "Batch   210  of    774.    Elapsed: 0:09:10.\n",
            "Batch   220  of    774.    Elapsed: 0:09:36.\n",
            "Batch   230  of    774.    Elapsed: 0:10:02.\n",
            "Batch   240  of    774.    Elapsed: 0:10:29.\n",
            "Batch   250  of    774.    Elapsed: 0:10:55.\n",
            "Batch   260  of    774.    Elapsed: 0:11:21.\n",
            "Batch   270  of    774.    Elapsed: 0:11:47.\n",
            "Batch   280  of    774.    Elapsed: 0:12:13.\n",
            "Batch   290  of    774.    Elapsed: 0:12:40.\n",
            "Batch   300  of    774.    Elapsed: 0:13:06.\n",
            "Batch   310  of    774.    Elapsed: 0:13:32.\n",
            "Batch   320  of    774.    Elapsed: 0:13:58.\n",
            "Batch   330  of    774.    Elapsed: 0:14:25.\n",
            "Batch   340  of    774.    Elapsed: 0:14:51.\n",
            "Batch   350  of    774.    Elapsed: 0:15:17.\n",
            "Batch   360  of    774.    Elapsed: 0:15:43.\n",
            "Batch   370  of    774.    Elapsed: 0:16:09.\n",
            "Batch   380  of    774.    Elapsed: 0:16:36.\n",
            "Batch   390  of    774.    Elapsed: 0:17:02.\n",
            "Batch   400  of    774.    Elapsed: 0:17:28.\n",
            "Batch   410  of    774.    Elapsed: 0:17:54.\n",
            "Batch   420  of    774.    Elapsed: 0:18:20.\n",
            "Batch   430  of    774.    Elapsed: 0:18:47.\n",
            "Batch   440  of    774.    Elapsed: 0:19:13.\n",
            "Batch   450  of    774.    Elapsed: 0:19:39.\n",
            "Batch   460  of    774.    Elapsed: 0:20:05.\n",
            "Batch   470  of    774.    Elapsed: 0:20:32.\n",
            "Batch   480  of    774.    Elapsed: 0:20:58.\n",
            "Batch   490  of    774.    Elapsed: 0:21:24.\n",
            "Batch   500  of    774.    Elapsed: 0:21:50.\n",
            "Batch   510  of    774.    Elapsed: 0:22:16.\n",
            "Batch   520  of    774.    Elapsed: 0:22:42.\n",
            "Batch   530  of    774.    Elapsed: 0:23:09.\n",
            "Batch   540  of    774.    Elapsed: 0:23:35.\n",
            "Batch   550  of    774.    Elapsed: 0:24:01.\n",
            "Batch   560  of    774.    Elapsed: 0:24:27.\n",
            "Batch   570  of    774.    Elapsed: 0:24:54.\n",
            "Batch   580  of    774.    Elapsed: 0:25:20.\n",
            "Batch   590  of    774.    Elapsed: 0:25:46.\n",
            "Batch   600  of    774.    Elapsed: 0:26:12.\n",
            "Batch   610  of    774.    Elapsed: 0:26:38.\n",
            "Batch   620  of    774.    Elapsed: 0:27:05.\n",
            "Batch   630  of    774.    Elapsed: 0:27:31.\n",
            "Batch   640  of    774.    Elapsed: 0:27:57.\n",
            "Batch   650  of    774.    Elapsed: 0:28:23.\n",
            "Batch   660  of    774.    Elapsed: 0:28:49.\n",
            "Batch   670  of    774.    Elapsed: 0:29:16.\n",
            "Batch   680  of    774.    Elapsed: 0:29:42.\n",
            "Batch   690  of    774.    Elapsed: 0:30:08.\n",
            "Batch   700  of    774.    Elapsed: 0:30:34.\n",
            "Batch   710  of    774.    Elapsed: 0:31:00.\n",
            "Batch   720  of    774.    Elapsed: 0:31:26.\n",
            "Batch   730  of    774.    Elapsed: 0:31:53.\n",
            "Batch   740  of    774.    Elapsed: 0:32:19.\n",
            "Batch   750  of    774.    Elapsed: 0:32:45.\n",
            "Batch   760  of    774.    Elapsed: 0:33:11.\n",
            "Batch   770  of    774.    Elapsed: 0:33:37.\n",
            "\n",
            "Average training loss: 0.80\n",
            "Training epcoh time: 0:33:47\n",
            "\n",
            "begin validation\n",
            "Accuracy: 0.69\n",
            "Validation Loss: 1.11\n",
            "Validation time: 0:02:16\n",
            "training complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AUtED1dxKLV",
        "colab_type": "text"
      },
      "source": [
        "Evaluating model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89Fj-GtqxDps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# switch model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "pred_labels = []\n",
        "true_labels = []\n",
        "\n",
        "for batch in test_loader:\n",
        "\n",
        "    b_inputs = batch[0].to(device)\n",
        "    b_attention_masks = batch[1].to(device)\n",
        "    b_label = batch[2].to(device) \n",
        "    \n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_inputs,\n",
        "                      attention_mask=b_attention_masks)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    labels = b_label.to('cpu').numpy()\n",
        "    \n",
        "    # Store predictions and true labels\n",
        "    pred_labels.append(logits)\n",
        "    true_labels.append(labels)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOyjPQnMgxoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "d6aa9d8b-eb97-4583-af30-a88c4e2e21c0"
      },
      "source": [
        "flat_pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "flat_pred_labels = np.argmax(flat_pred_labels, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "print(classification_report(flat_true_labels, flat_pred_labels))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       309\n",
            "           1       0.74      0.54      0.63        59\n",
            "           2       0.70      0.84      0.76        63\n",
            "           3       0.66      0.72      0.69       126\n",
            "           4       0.00      0.00      0.00        15\n",
            "           5       0.66      0.80      0.73        46\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.75      0.60      0.67        10\n",
            "           8       0.00      0.00      0.00         4\n",
            "           9       0.70      0.76      0.73       307\n",
            "          10       0.61      0.54      0.58       123\n",
            "          11       0.71      0.73      0.72        97\n",
            "          12       0.00      0.00      0.00        14\n",
            "          13       1.00      0.25      0.40         4\n",
            "          14       0.68      0.54      0.60        35\n",
            "          15       0.00      0.00      0.00         1\n",
            "          16       0.00      0.00      0.00         3\n",
            "          17       0.67      0.22      0.33         9\n",
            "          18       0.58      0.61      0.59       424\n",
            "          19       0.47      0.28      0.35        57\n",
            "          20       0.00      0.00      0.00         4\n",
            "          23       0.85      0.88      0.86        57\n",
            "\n",
            "    accuracy                           0.68      1768\n",
            "   macro avg       0.48      0.42      0.43      1768\n",
            "weighted avg       0.66      0.68      0.67      1768\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRJspLxkmTU6",
        "colab_type": "text"
      },
      "source": [
        "Saving model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFowGMHVbF6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "89f6426f-3fd3-48ed-af74-ff78720e4b86"
      },
      "source": [
        "import os\n",
        "\n",
        "output_dir = '/content/gdrive/My Drive/Amazon Seller Forum/xlnet_model/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to /content/gdrive/My Drive/Amazon Seller Forum/xlnet_model/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/gdrive/My Drive/Amazon Seller Forum/xlnet_model/spiece.model',\n",
              " '/content/gdrive/My Drive/Amazon Seller Forum/xlnet_model/special_tokens_map.json',\n",
              " '/content/gdrive/My Drive/Amazon Seller Forum/xlnet_model/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIe6oDGWmWyy",
        "colab_type": "text"
      },
      "source": [
        "loading model for futre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3Qz9GyXmX1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "#model = ppb.BertForSequenceClassification.from_pretrained(output_dir)\n",
        "#tokenizer = ppb.DistilBertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "#model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3THMeHz-qcJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}