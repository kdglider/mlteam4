import requests
from bs4 import BeautifulSoup
import pandas as pd

base = "https://forum.flowster.app/"
response = requests.get(base)
soup = BeautifulSoup(response.text, 'html.parser')

lead_c=[]
tags_c=[]
topic_c=[]
rest_c=[]

def get_links(num_elem=None):
#create the demanded num of links with a base provided
    access_url = soup.find_all('a')
    links = []
    for item in access_url:
        links.append(base+item.get('href'))
    if isinstance(num_elem, int):
        links = links[1:num_elem+1]
        return links
    return links[1:]

#create a list that contains the urls of the first layer of categories
category_link = get_links(12)

for category in category_link:
    page = requests.get(category)
    soup = BeautifulSoup(page.text, 'html.parser')
    
    temp = []
    topic_link = []
    temp = soup.find_all('a',class_="title raw-link raw-topic-link")
    for link in temp:
        topic_link.append(link.get('href'))

    for topic in topic_link:
        page = requests.get(topic)
        soup = BeautifulSoup(page.text, 'html.parser') 
        temp_tag = []
        #print(soup.prettify())
        
        #get the leading comment under each topic
        for j in soup.find_all('meta',property='og:description'):
            lead = j.get('content')
            lead_c.append(lead)
            
        #get tags for each topic and form them into a list of lists
        #we want a list of list so that the tag_c length matches up with the topic_c length
        for n in soup.find_all('span', class_="category-name"):
            temp_tag.append(n.getText())
        tags_c.append(temp_tag)
        
        #get the topic title
        for i in soup.find_all("meta", property="og:title"):
            topic = i.get("content")
            topic_c.append(topic)

#below line currently outputs "182, 185, 183", and because the size does not match. I cannot generate a data table           
print(len(lead_c), len(tags_c), len(topic_c))

data = {'Topic': topic_c,'Lead_c': lead_c, 'Tags': tags_c, }
df=pd.DataFrame(data=data)
