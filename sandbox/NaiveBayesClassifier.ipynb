{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NaiveBayesClassifier.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMThbcMM9dcz9lBBPa1zqJr"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0OMbSIhfAnm7","colab_type":"text"},"source":["### Mount Google Drive to runtime"]},{"cell_type":"code","metadata":{"id":"Xn1Lg82b3-0w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":157},"executionInfo":{"status":"ok","timestamp":1592674146612,"user_tz":240,"elapsed":47222,"user":{"displayName":"Kevin Dong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrfvovL_K-EjzSiy9r2BbO6ZCCRF-0rJdjiFmRUQ=s64","userId":"03761071086123068512"}},"outputId":"7ab949ac-aeea-4476-c855-0a2db6b5463c"},"source":["from google.colab import drive\n","from os.path import join\n","\n","# Mounting location on runtime for GDrive\n","ROOT = '/content/drive'\n","\n","# Project workspace on GDrive\n","PROJECT_PATH = 'My Drive/Github'\n","\n","# Mount GDrive on the runtime\n","drive.mount(ROOT)\n","\n","# Create the full runtime project path and create a workspace at that location\n","WORKING_PATH = join(ROOT, PROJECT_PATH)\n","!mkdir \"{WORKING_PATH}\" \n","%cd \"{WORKING_PATH}\""],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","mkdir: cannot create directory ‘/content/drive/My Drive/Github’: File exists\n","/content/drive/My Drive/Github\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ue0YZTGpAhRw","colab_type":"text"},"source":["### Import libraries"]},{"cell_type":"code","metadata":{"id":"gB9rvz2UhOUv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"executionInfo":{"status":"ok","timestamp":1592510730739,"user_tz":240,"elapsed":2147,"user":{"displayName":"Kevin Dong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrfvovL_K-EjzSiy9r2BbO6ZCCRF-0rJdjiFmRUQ=s64","userId":"03761071086123068512"}},"outputId":"ce455708-e622-4a49-dbc7-f7bb61fe1759"},"source":["import json\n","import string\n","\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xrE_Ob15rfck","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1eAHPSd5Mlv4rfTeOSTCw28g05wlDQd_V"},"executionInfo":{"status":"ok","timestamp":1592512408248,"user_tz":240,"elapsed":18880,"user":{"displayName":"Kevin Dong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrfvovL_K-EjzSiy9r2BbO6ZCCRF-0rJdjiFmRUQ=s64","userId":"03761071086123068512"}},"outputId":"a1740005-9941-49d5-f3a3-f02f3a776ee2"},"source":["def is_ascii(s):\n","    return all(ord(c) < 128 for c in s)\n","\n","f = open('/content/drive/My Drive/Github/mlteam4/sandbox/Amazon_Topic_Attributes_20200617061621.json')\n","topicDict = json.load(f)\n","f.close()\n","\n","topics = list(topicDict.keys())\n","\n","topicFeatures = []\n","labels = []\n","\n","count = 0\n","for topic in topics:\n","    # Combine topic title and comments into one string\n","    title = topicDict[topic]['Topic Title']\n","    leadingComment = topicDict[topic]['Leading Comment']\n","    #otherComments = topicDict[topic]['Other Comments']\n","    \n","    commentList = [title] + [leadingComment] \n","    featureString = ' '.join(commentList)\n","\n","    # Replace newline and tab characters with spaces\n","    featureString = featureString.replace('\\n', ' ')\n","    featureString = featureString.replace('\\t', ' ')\n","\n","    # Convert all letters to lowercase\n","    featureString = featureString.lower()\n","\n","    table = str.maketrans('', '', string.punctuation)\n","    #featureString = featureString.translate(table)\n","\n","    #featureString = featureString.encode(encoding='ascii', errors='ignore').decode('ascii')\n","\n","    wordList = featureString.split()\n","\n","    stop_words = set(stopwords.words('english'))\n","    wordList = [word for word in wordList if not word in stop_words]\n","\n","    wordList = [word for word in wordList if is_ascii(word)]\n","\n","    punctuation = '!\"#%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n","    wordList = [word.strip(punctuation) for word in wordList]\n","\n","    wordList = ['########' if (word.replace('.','').isdigit()) \\\n","                else '$$$$$$$$' if (word.replace('.','').replace('$','').isdigit()) \\\n","                else word \\\n","                for word in wordList]\n","\n","    #print(wordList)\n","    #wordList = ['########' if (word.replace('.','').isdigit()) else word for word in wordList]\n","    #wordList = ['########' if (word.translate(table).isdigit()) else word for word in wordList]\n","    \n","\n","    #wordList = [word for word in wordList if word.isalpha()]\n","\n","    \n","\n","    #table = str.maketrans('', '', string.punctuation)\n","    #wordList = [w.translate(table) for w in wordList]\n","\n","    #print(wordList)\n","\n","    featureString = ' '.join(wordList)\n","    if (featureString.strip() == ''):\n","        continue\n","    print(count)\n","    count += 1\n","    print(featureString)\n","\n","    topicFeatures.append(featureString)\n","\n","    # Append topic category to ground truth labels\n","    labels.append(topicDict[topic]['Category'])\n","\n","\n","\n","vectorizer = CountVectorizer()\n","#vectorizer = TfidfVectorizer()\n","\n","X = vectorizer.fit_transform(topicFeatures)\n","\n","#X = 1000 * X\n","\n","print(X.toarray())\n","print(X.shape)\n","#print(len(vectorizer.get_feature_names()))\n","\n","#print(labels)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.1)\n","#X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.1, random_state=8)\n","#print(X_test.shape)\n","\n","multinominalClassifier = MultinomialNB()\n","multinominalClassifier.fit(X_train, y_train)\n","\n","numCorrect = (multinominalClassifier.predict(X_test) == y_test).sum()\n","accuracy = numCorrect / len(y_test)\n","print('Multinominal Classifier Accuracy: ' + str(accuracy))\n","\n","gaussianClassifier = GaussianNB()\n","gaussianClassifier.fit(X_train.toarray(), y_train)\n","\n","numCorrect = (gaussianClassifier.predict(X_test.toarray()) == y_test).sum()\n","accuracy = numCorrect / len(y_test)\n","print('Gausian Classifier Accuracy: ' + str(accuracy))\n","\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}