{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_GJ_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ecec10ae024542c8b00f21cea8c8ac10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_030ce0da5a54425cb78e046e592256f2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6bf77cbce4bf422284c568afd090966f",
              "IPY_MODEL_f39d3bda14794523bf7efac9e26ec7c9"
            ]
          }
        },
        "030ce0da5a54425cb78e046e592256f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6bf77cbce4bf422284c568afd090966f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_49383960d1b44f43900184636330729a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2963fcb86f0444a3b5c59a6bb3fbb6a9"
          }
        },
        "f39d3bda14794523bf7efac9e26ec7c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f64cd1ff69ff45a4abee8e30a047c602",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 688kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b8746f741074c25afc53b46352d5301"
          }
        },
        "49383960d1b44f43900184636330729a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2963fcb86f0444a3b5c59a6bb3fbb6a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f64cd1ff69ff45a4abee8e30a047c602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b8746f741074c25afc53b46352d5301": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89e250825f9a457faf911af52587c4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6e4e289e44b242448afc1252e4dca315",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4603a75a14f7455c910b9e6b6af4e9a5",
              "IPY_MODEL_2fd66285078945fbbf4fc994eff6e3e8"
            ]
          }
        },
        "6e4e289e44b242448afc1252e4dca315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4603a75a14f7455c910b9e6b6af4e9a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b0e97865fe2440a592170cab2e76f90b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61d164fcdf46484693244bec42440466"
          }
        },
        "2fd66285078945fbbf4fc994eff6e3e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_791519e5b0774690885534142ccf109d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:09&lt;00:00, 45.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3839547974e44148b7a8d42603d151e3"
          }
        },
        "b0e97865fe2440a592170cab2e76f90b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61d164fcdf46484693244bec42440466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "791519e5b0774690885534142ccf109d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3839547974e44148b7a8d42603d151e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1a2f46eee0c4fb19d33f93cb4c29659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ebdef80526474d109c29d4e7beb30f31",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8065763e74d14085b6af3d94e6cb2948",
              "IPY_MODEL_8223b76f8f5740dcb8132d24474d2b71"
            ]
          }
        },
        "ebdef80526474d109c29d4e7beb30f31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8065763e74d14085b6af3d94e6cb2948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a1e8c3c2f5c840d7aba6fefb4b81c768",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04ef25c644a54ad68aa356a88143f0c6"
          }
        },
        "8223b76f8f5740dcb8132d24474d2b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1fd4ecc4ddd849b8ae483a62a6660c7e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:09&lt;00:00, 28.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2123768639e74395bfab13fdae2dec56"
          }
        },
        "a1e8c3c2f5c840d7aba6fefb4b81c768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04ef25c644a54ad68aa356a88143f0c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fd4ecc4ddd849b8ae483a62a6660c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2123768639e74395bfab13fdae2dec56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pl1jAjg5CJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "a8539765-b4c8-4f6b-b3ab-64fe2fe8ee30"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB0VMrmZkDct",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "2ae43160-dc7e-48cc-8fd2-be8d13385fc9"
      },
      "source": [
        "# If running type is GPU, run this cell\n",
        "\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "\n",
        "printm()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=53d496ab661082ccf843c37c6ef1a5fefcad3e108f9396a6d927c47b6e480bd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 161.3 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOdDEIK9d4W1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If run type is TPU, run this cell \n",
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n",
        "\n",
        "try:\n",
        "  # imports the torch_xla package\n",
        "  import torch_xla\n",
        "  import torch_xla.core.xla_model as xm\n",
        "\n",
        "  device = xm.xla_device()\n",
        "\n",
        "except:\n",
        "  VERSION = \"20200325\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "  !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "  !python pytorch-xla-env-setup.py --version $VERSION\n",
        "\n",
        "  # imports pytorch\n",
        "  import torch\n",
        "\n",
        "  # imports the torch_xla package\n",
        "  import torch_xla\n",
        "  import torch_xla.core.xla_model as xm\n",
        "\n",
        "  device = xm.xla_device()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLPPEaiL6NOf",
        "colab_type": "text"
      },
      "source": [
        "Python library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CIkr-Lq5bYV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "600ea8e1-0a38-490d-e8ac-35cc0275cdfc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "from html.parser import HTMLParser\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "try:\n",
        "  import transformers as ppb\n",
        "except:\n",
        "  !pip install transformers\n",
        "  import transformers as ppb\n",
        "\n",
        "from transformers import AdamW, BertConfig, get_linear_schedule_with_warmup"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 757kB 6.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 18.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 38.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 40.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=de541b37361687dc5c13233be5edb79ac9ad07317336048360ab8269195e44b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.0rc4 transformers-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mospiZM4LRjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e7a13923-5c62-4bfb-f001-a6d8144575a0"
      },
      "source": [
        "# If running on GPU, run this cell to enable cuda\n",
        "if torch.cuda.is_available():    \n",
        "  \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRxQICFkcHcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_cleaning(text):\n",
        "    # converting HTML character codes to ASCII code\n",
        "    parser = HTMLParser()\n",
        "    text = parser.unescape(text)\n",
        "\n",
        "    text = re.sub(r'<[^>]+>', '', text)  # removing HTML tags\n",
        "    text = re.sub(r'(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)', '', text)  # removing hash-tags\n",
        "    text = re.sub('\\n', ' ', text)  # remove new line\n",
        "    text = re.sub('@', '', text)  # remove @ sign\n",
        "    #text = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', '',text)  # removing URLs\n",
        "    text = re.sub(r'(?:[\\ufffd]+)', '', text)  # removing special characters\n",
        "    text = text.lower()\n",
        "\n",
        "    return text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_dlz6sBVIp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "    # display the elapsed time when loading the data into the BERT model\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JD4_tcwtsKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(pred, true):\n",
        "    pred_flat = np.argmax(pred, axis=1).flatten()\n",
        "    true_flat = true.flatten()\n",
        "    return np.sum(pred_flat == true_flat) / len(true_flat)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46005IXE8-Ya",
        "colab_type": "text"
      },
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsTZwBST6rd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/gdrive/My Drive/Amazon Seller Forum/final_merged_data.csv')\n",
        "df.drop('Unnamed: 0',axis=1,inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hD5Y4fV61hp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "5f94f8fc-3997-41fc-c9be-b10b800a2015"
      },
      "source": [
        "print(df.isna().sum())\n",
        "print('')\n",
        "\n",
        "nan_row = np.where(df.isna())[0][0]\n",
        "print(df.iloc[nan_row,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title              0\n",
            "Post Author        0\n",
            "Leading Comment    1\n",
            "Reply Comments     0\n",
            "Category           0\n",
            "Forum              0\n",
            "dtype: int64\n",
            "\n",
            "Title              Israel Cohenâ€™s Success Story1\n",
            "Post Author                          Trent-Admin\n",
            "Leading Comment                              NaN\n",
            "Reply Comments                                []\n",
            "Category                             Misc Topics\n",
            "Forum                                   Flowster\n",
            "Name: 8832, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9sjJiTnk_1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dropna(axis=0,subset=['Leading Comment'],inplace = True)\n",
        "df.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve8t228ogSoo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "3f4cddb7-7873-48d7-e886-ac0db9c4ae0c"
      },
      "source": [
        "df['Category'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Selling on Amazon                                     2100\n",
              "Account Health                                        1549\n",
              "Fulfillment By Amazon                                 1500\n",
              "Global Selling                                         600\n",
              "Amazon Pay                                             600\n",
              "Groups                                                 494\n",
              "Site Feedback                                          300\n",
              "Amazon Marketplace Web Service (MWS)                   300\n",
              "US Announcements                                       300\n",
              "Amazon Sponsored Products                              300\n",
              "Amazon Custom                                          274\n",
              "Login With Amazon                                      199\n",
              "Health,Safety,Sustainability,Security & Compliance      63\n",
              "Flowster-specific                                       59\n",
              "Amazon Specific                                         53\n",
              "Product Sourcing                                        53\n",
              "Human Resources                                         21\n",
              "Fulfillment                                             17\n",
              "Management                                              15\n",
              "Software & Tools                                        14\n",
              "Misc Topics                                             10\n",
              "Traffic Sources                                          8\n",
              "Financial Management                                     8\n",
              "eCommerce Marketplaces                                   2\n",
              "Store & Website Management                               1\n",
              "Name: Category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CTP01VCKT8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['num_sent'] = df['Leading Comment'].apply(lambda x: len(sent_tokenize(x)))\n",
        "df['num_word']= df['Leading Comment'].apply(lambda x: len(word_tokenize(x)))\n",
        "df['num_capword_title'] = df['Title'].apply(lambda x: sum(word[0].isupper() for word in word_tokenize(x)))\n",
        "\n",
        "row_drop_idx = df[df['Category'] == 'Store & Website Management'].index[0]\n",
        "\n",
        "df.drop(df.index[row_drop_idx],inplace=True)\n",
        "df.reset_index(drop=True,inplace=True)\n",
        "\n",
        "row_drop_idx = df[df['Category'] == 'eCommerce Marketplaces'].index[0]\n",
        "df.drop(df.index[row_drop_idx],inplace=True)\n",
        "df.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8KBi3rfbTBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comments = df['Leading Comment'].apply(lambda x:text_cleaning(x))\n",
        "#df['corpus'] = df['Title']+\" \"+ df['Leading Comment']\n",
        "#df['corpus'] = df['corpus'].apply(lambda x:text_cleaning(x))\n",
        "#corpus = df['corpus']\n",
        "\n",
        "#df_amazon = df[df['Forum']=='Amazon']\n",
        "#comments = df_amazon['Leading Comment'].apply(lambda x:text_cleaning(x))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B90MRkL8869b",
        "colab_type": "text"
      },
      "source": [
        "Load Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf2hlrox63ES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ecec10ae024542c8b00f21cea8c8ac10",
            "030ce0da5a54425cb78e046e592256f2",
            "6bf77cbce4bf422284c568afd090966f",
            "f39d3bda14794523bf7efac9e26ec7c9",
            "49383960d1b44f43900184636330729a",
            "2963fcb86f0444a3b5c59a6bb3fbb6a9",
            "f64cd1ff69ff45a4abee8e30a047c602",
            "8b8746f741074c25afc53b46352d5301",
            "89e250825f9a457faf911af52587c4cf",
            "6e4e289e44b242448afc1252e4dca315",
            "4603a75a14f7455c910b9e6b6af4e9a5",
            "2fd66285078945fbbf4fc994eff6e3e8",
            "b0e97865fe2440a592170cab2e76f90b",
            "61d164fcdf46484693244bec42440466",
            "791519e5b0774690885534142ccf109d",
            "3839547974e44148b7a8d42603d151e3",
            "c1a2f46eee0c4fb19d33f93cb4c29659",
            "ebdef80526474d109c29d4e7beb30f31",
            "8065763e74d14085b6af3d94e6cb2948",
            "8223b76f8f5740dcb8132d24474d2b71",
            "a1e8c3c2f5c840d7aba6fefb4b81c768",
            "04ef25c644a54ad68aa356a88143f0c6",
            "1fd4ecc4ddd849b8ae483a62a6660c7e",
            "2123768639e74395bfab13fdae2dec56"
          ]
        },
        "outputId": "7a17fa1a-00e6-48ae-af42-36d54facb753"
      },
      "source": [
        "#from transformers import XLNetLMHeadModel, XLNetTokenizer\n",
        "\n",
        "#tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
        "#model = XLNetLMHeadModel.from_pretrained(\"xlnet-base-cased\",\n",
        "                                         #output_attentions = False, # Whether the model returns attentions weights.\n",
        "                                         #output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "                                         #)\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertForSequenceClassification, ppb.BertTokenizer, 'bert-base-cased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "\n",
        "tokenizer = ppb.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "model = ppb.DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',num_labels=24)\n",
        "model.to(device)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ecec10ae024542c8b00f21cea8c8ac10",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89e250825f9a457faf911af52587c4cf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1a2f46eee0c4fb19d33f93cb4c29659",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=24, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6CJFDQB9z4v",
        "colab_type": "text"
      },
      "source": [
        "tokenize leading comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2HQvrIX9u2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_encoder = LabelEncoder()\n",
        "inputs = []\n",
        "attention_masks = []\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "    #   1. Tokenize the sentence.\n",
        "    #   2. Prepend the `[CLS]` token to the start.\n",
        "    #   3. Append the `[SEP]` token to the end.\n",
        "    #   4. Map tokens to their IDs.\n",
        "    #   5. Pad or truncate the sentence to `max_length`\n",
        "    #   6. Create attention masks for [PAD] tokens.\n",
        "\n",
        "for comment in comments:\n",
        "#for comment in corpus:\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        comment,                      \n",
        "                        add_special_tokens = True, \n",
        "                        truncation=True,\n",
        "                        max_length = 512,           \n",
        "                        pad_to_max_length = True,\n",
        "                        return_overflowing_tokens=True,\n",
        "                        stride=70,\n",
        "                        return_attention_mask = True,  \n",
        "                        return_tensors = 'pt',     \n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    inputs.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors and load them to GPU/TPU\n",
        "inputs = torch.cat(inputs, dim=0)#.to(device)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)#.to(device)\n",
        "\n",
        "# Encoding the labels and convert them to tensor \n",
        "labels = label_encoder.fit_transform(df['Category'])\n",
        "labels = torch.tensor(labels)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twavs2Iwbpsf",
        "colab_type": "text"
      },
      "source": [
        "Prepare training dataset and validating dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akYLG2DmboLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_size = int(len(comments)*0.7)\n",
        "val_size = int(len(comments)*0.1)\n",
        "test_size = len(comments) - train_size - val_size\n",
        "\n",
        "dataset = TensorDataset(inputs,attention_masks,labels)\n",
        "\n",
        "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, sampler = RandomSampler(train_set), batch_size = batch_size)\n",
        "\n",
        "val_loader = DataLoader(val_set, sampler = SequentialSampler(val_set), batch_size = batch_size)\n",
        "\n",
        "test_loader = DataLoader(test_set, sampler = SequentialSampler(test_set), batch_size = batch_size)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozQz6Zzih1o4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, \n",
        "                  eps = 1e-8)\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps = [number of batches]*[number of epochs]. \n",
        "total_steps = len(train_loader)*epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3CM8rGPfPHc",
        "colab_type": "text"
      },
      "source": [
        "Training Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFiZuDZXe79f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc622e3a-d2a7-4b29-d97b-aacbcbcbc1a1"
      },
      "source": [
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_log = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  time_start = time.time()\n",
        "  total_train_loss = 0\n",
        "\n",
        "  print('begin training')\n",
        "  print('')\n",
        "\n",
        "  model.train()\n",
        "  \n",
        "  for step, batch in enumerate(train_loader):\n",
        "    if step % 10 == 0 and not step == 0:\n",
        "      elapsed = format_time(time.time()-time_start)\n",
        "      print('Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_loader), elapsed))\n",
        "    \n",
        "    b_inputs = batch[0].to(device)\n",
        "    b_attention_masks = batch[1].to(device)\n",
        "    b_label = batch[2].to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "    loss, logit = model(b_inputs,attention_mask=b_attention_masks, labels = b_label)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    total_train_loss += loss.item()\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    \n",
        "\n",
        "  avg_train_loss = total_train_loss/len(train_loader)\n",
        "  training_time = format_time(time.time() - time_start)\n",
        "  print('')\n",
        "  print('Average training loss: {0:.2f}'.format(avg_train_loss))\n",
        "  print('Training epcoh time: {:}'.format(training_time))\n",
        "  \n",
        "  print('')\n",
        "  print('begin validation')\n",
        "\n",
        "  time_start = time.time()\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  total_eval_acc = 0\n",
        "  total_eval_loss = 0\n",
        "  nb_eval_steps = 0\n",
        "\n",
        "  for batch in val_loader:\n",
        "    b_inputs = batch[0].cuda()\n",
        "    b_attention_masks = batch[1].cuda()\n",
        "    b_label = batch[2].cuda() \n",
        "\n",
        "    with torch.no_grad():\n",
        "      (loss, logits) = model(b_inputs,attention_mask=b_attention_masks, labels = b_label)\n",
        "\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label = b_label.to('cpu').numpy()\n",
        "\n",
        "    total_eval_acc += get_accuracy(logits, label)\n",
        "  \n",
        "  avg_val_accuracy = total_eval_acc/len(val_loader)\n",
        "  print(\"Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "  avg_val_loss = total_eval_loss/len(val_loader)\n",
        "\n",
        "  validation_time = format_time(time.time() - time_start)\n",
        "  \n",
        "  print(\"Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "  print(\"Validation time: {:}\".format(validation_time))\n",
        "\n",
        "  training_log.append(\n",
        "        {\n",
        "            'epoch': epoch+1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "  \n",
        "print('training complete')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin training\n",
            "\n",
            "Batch    10  of    387.    Elapsed: 0:00:15.\n",
            "Batch    20  of    387.    Elapsed: 0:00:30.\n",
            "Batch    30  of    387.    Elapsed: 0:00:45.\n",
            "Batch    40  of    387.    Elapsed: 0:01:00.\n",
            "Batch    50  of    387.    Elapsed: 0:01:15.\n",
            "Batch    60  of    387.    Elapsed: 0:01:29.\n",
            "Batch    70  of    387.    Elapsed: 0:01:44.\n",
            "Batch    80  of    387.    Elapsed: 0:01:59.\n",
            "Batch    90  of    387.    Elapsed: 0:02:14.\n",
            "Batch   100  of    387.    Elapsed: 0:02:29.\n",
            "Batch   110  of    387.    Elapsed: 0:02:44.\n",
            "Batch   120  of    387.    Elapsed: 0:02:58.\n",
            "Batch   130  of    387.    Elapsed: 0:03:13.\n",
            "Batch   140  of    387.    Elapsed: 0:03:28.\n",
            "Batch   150  of    387.    Elapsed: 0:03:43.\n",
            "Batch   160  of    387.    Elapsed: 0:03:58.\n",
            "Batch   170  of    387.    Elapsed: 0:04:13.\n",
            "Batch   180  of    387.    Elapsed: 0:04:28.\n",
            "Batch   190  of    387.    Elapsed: 0:04:42.\n",
            "Batch   200  of    387.    Elapsed: 0:04:57.\n",
            "Batch   210  of    387.    Elapsed: 0:05:12.\n",
            "Batch   220  of    387.    Elapsed: 0:05:27.\n",
            "Batch   230  of    387.    Elapsed: 0:05:42.\n",
            "Batch   240  of    387.    Elapsed: 0:05:56.\n",
            "Batch   250  of    387.    Elapsed: 0:06:11.\n",
            "Batch   260  of    387.    Elapsed: 0:06:26.\n",
            "Batch   270  of    387.    Elapsed: 0:06:41.\n",
            "Batch   280  of    387.    Elapsed: 0:06:56.\n",
            "Batch   290  of    387.    Elapsed: 0:07:11.\n",
            "Batch   300  of    387.    Elapsed: 0:07:25.\n",
            "Batch   310  of    387.    Elapsed: 0:07:40.\n",
            "Batch   320  of    387.    Elapsed: 0:07:55.\n",
            "Batch   330  of    387.    Elapsed: 0:08:10.\n",
            "Batch   340  of    387.    Elapsed: 0:08:25.\n",
            "Batch   350  of    387.    Elapsed: 0:08:39.\n",
            "Batch   360  of    387.    Elapsed: 0:08:54.\n",
            "Batch   370  of    387.    Elapsed: 0:09:09.\n",
            "Batch   380  of    387.    Elapsed: 0:09:24.\n",
            "\n",
            "Average training loss: 1.24\n",
            "Training epcoh time: 0:09:34\n",
            "\n",
            "begin validation\n",
            "Accuracy: 0.63\n",
            "  Validation Loss: 1.25\n",
            "  Validation time: 0:00:30\n",
            "begin training\n",
            "\n",
            "Batch    10  of    387.    Elapsed: 0:00:15.\n",
            "Batch    20  of    387.    Elapsed: 0:00:30.\n",
            "Batch    30  of    387.    Elapsed: 0:00:44.\n",
            "Batch    40  of    387.    Elapsed: 0:00:59.\n",
            "Batch    50  of    387.    Elapsed: 0:01:14.\n",
            "Batch    60  of    387.    Elapsed: 0:01:29.\n",
            "Batch    70  of    387.    Elapsed: 0:01:44.\n",
            "Batch    80  of    387.    Elapsed: 0:01:59.\n",
            "Batch    90  of    387.    Elapsed: 0:02:14.\n",
            "Batch   100  of    387.    Elapsed: 0:02:28.\n",
            "Batch   110  of    387.    Elapsed: 0:02:43.\n",
            "Batch   120  of    387.    Elapsed: 0:02:58.\n",
            "Batch   130  of    387.    Elapsed: 0:03:13.\n",
            "Batch   140  of    387.    Elapsed: 0:03:28.\n",
            "Batch   150  of    387.    Elapsed: 0:03:42.\n",
            "Batch   160  of    387.    Elapsed: 0:03:57.\n",
            "Batch   170  of    387.    Elapsed: 0:04:12.\n",
            "Batch   180  of    387.    Elapsed: 0:04:27.\n",
            "Batch   190  of    387.    Elapsed: 0:04:42.\n",
            "Batch   200  of    387.    Elapsed: 0:04:56.\n",
            "Batch   210  of    387.    Elapsed: 0:05:11.\n",
            "Batch   220  of    387.    Elapsed: 0:05:26.\n",
            "Batch   230  of    387.    Elapsed: 0:05:41.\n",
            "Batch   240  of    387.    Elapsed: 0:05:56.\n",
            "Batch   250  of    387.    Elapsed: 0:06:11.\n",
            "Batch   260  of    387.    Elapsed: 0:06:25.\n",
            "Batch   270  of    387.    Elapsed: 0:06:40.\n",
            "Batch   280  of    387.    Elapsed: 0:06:55.\n",
            "Batch   290  of    387.    Elapsed: 0:07:10.\n",
            "Batch   300  of    387.    Elapsed: 0:07:25.\n",
            "Batch   310  of    387.    Elapsed: 0:07:39.\n",
            "Batch   320  of    387.    Elapsed: 0:07:54.\n",
            "Batch   330  of    387.    Elapsed: 0:08:09.\n",
            "Batch   340  of    387.    Elapsed: 0:08:24.\n",
            "Batch   350  of    387.    Elapsed: 0:08:39.\n",
            "Batch   360  of    387.    Elapsed: 0:08:54.\n",
            "Batch   370  of    387.    Elapsed: 0:09:08.\n",
            "Batch   380  of    387.    Elapsed: 0:09:23.\n",
            "\n",
            "Average training loss: 1.06\n",
            "Training epcoh time: 0:09:33\n",
            "\n",
            "begin validation\n",
            "Accuracy: 0.65\n",
            "  Validation Loss: 1.20\n",
            "  Validation time: 0:00:30\n",
            "begin training\n",
            "\n",
            "Batch    10  of    387.    Elapsed: 0:00:15.\n",
            "Batch    20  of    387.    Elapsed: 0:00:30.\n",
            "Batch    30  of    387.    Elapsed: 0:00:45.\n",
            "Batch    40  of    387.    Elapsed: 0:00:59.\n",
            "Batch    50  of    387.    Elapsed: 0:01:14.\n",
            "Batch    60  of    387.    Elapsed: 0:01:29.\n",
            "Batch    70  of    387.    Elapsed: 0:01:44.\n",
            "Batch    80  of    387.    Elapsed: 0:01:59.\n",
            "Batch    90  of    387.    Elapsed: 0:02:14.\n",
            "Batch   100  of    387.    Elapsed: 0:02:28.\n",
            "Batch   110  of    387.    Elapsed: 0:02:43.\n",
            "Batch   120  of    387.    Elapsed: 0:02:58.\n",
            "Batch   130  of    387.    Elapsed: 0:03:13.\n",
            "Batch   140  of    387.    Elapsed: 0:03:28.\n",
            "Batch   150  of    387.    Elapsed: 0:03:43.\n",
            "Batch   160  of    387.    Elapsed: 0:03:58.\n",
            "Batch   170  of    387.    Elapsed: 0:04:12.\n",
            "Batch   180  of    387.    Elapsed: 0:04:27.\n",
            "Batch   190  of    387.    Elapsed: 0:04:42.\n",
            "Batch   200  of    387.    Elapsed: 0:04:57.\n",
            "Batch   210  of    387.    Elapsed: 0:05:12.\n",
            "Batch   220  of    387.    Elapsed: 0:05:26.\n",
            "Batch   230  of    387.    Elapsed: 0:05:41.\n",
            "Batch   240  of    387.    Elapsed: 0:05:56.\n",
            "Batch   250  of    387.    Elapsed: 0:06:11.\n",
            "Batch   260  of    387.    Elapsed: 0:06:26.\n",
            "Batch   270  of    387.    Elapsed: 0:06:41.\n",
            "Batch   280  of    387.    Elapsed: 0:06:55.\n",
            "Batch   290  of    387.    Elapsed: 0:07:10.\n",
            "Batch   300  of    387.    Elapsed: 0:07:25.\n",
            "Batch   310  of    387.    Elapsed: 0:07:40.\n",
            "Batch   320  of    387.    Elapsed: 0:07:55.\n",
            "Batch   330  of    387.    Elapsed: 0:08:10.\n",
            "Batch   340  of    387.    Elapsed: 0:08:25.\n",
            "Batch   350  of    387.    Elapsed: 0:08:39.\n",
            "Batch   360  of    387.    Elapsed: 0:08:54.\n",
            "Batch   370  of    387.    Elapsed: 0:09:09.\n",
            "Batch   380  of    387.    Elapsed: 0:09:24.\n",
            "\n",
            "Average training loss: 1.00\n",
            "Training epcoh time: 0:09:34\n",
            "\n",
            "begin validation\n",
            "Accuracy: 0.65\n",
            "  Validation Loss: 1.20\n",
            "  Validation time: 0:00:30\n",
            "training complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AUtED1dxKLV",
        "colab_type": "text"
      },
      "source": [
        "Evaluating model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89Fj-GtqxDps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# switch model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "pred_labels = []\n",
        "true_labels = []\n",
        "\n",
        "for batch in test_loader:\n",
        "\n",
        "    b_inputs = batch[0].to(device)\n",
        "    b_attention_masks = batch[1].to(device)\n",
        "    b_label = batch[2].to(device) \n",
        "    \n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_inputs,\n",
        "                      attention_mask=b_attention_masks)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    labels = b_label.to('cpu').numpy()\n",
        "    \n",
        "    # Store predictions and true labels\n",
        "    pred_labels.append(logits)\n",
        "    true_labels.append(labels)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOyjPQnMgxoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "14c02fc2-ce67-45f0-dcdc-65d7535a00fc"
      },
      "source": [
        "flat_pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "flat_pred_labels = np.argmax(flat_pred_labels, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "print(classification_report(flat_true_labels, flat_pred_labels))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.88      0.84       293\n",
            "           1       0.85      0.40      0.54        58\n",
            "           2       0.62      0.68      0.65        65\n",
            "           3       0.65      0.69      0.67       118\n",
            "           4       0.00      0.00      0.00        13\n",
            "           5       0.64      0.79      0.71        61\n",
            "           6       0.00      0.00      0.00         3\n",
            "           7       0.00      0.00      0.00        12\n",
            "           8       0.00      0.00      0.00         1\n",
            "           9       0.70      0.74      0.72       313\n",
            "          10       0.55      0.47      0.50       120\n",
            "          11       0.71      0.64      0.67        88\n",
            "          12       0.00      0.00      0.00        12\n",
            "          13       0.00      0.00      0.00         3\n",
            "          14       0.69      0.73      0.71        37\n",
            "          15       0.00      0.00      0.00         2\n",
            "          17       0.00      0.00      0.00        11\n",
            "          18       0.56      0.64      0.59       440\n",
            "          19       0.28      0.13      0.18        52\n",
            "          20       0.00      0.00      0.00         5\n",
            "          22       0.75      0.84      0.79        62\n",
            "\n",
            "    accuracy                           0.66      1769\n",
            "   macro avg       0.37      0.36      0.36      1769\n",
            "weighted avg       0.63      0.66      0.64      1769\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRJspLxkmTU6",
        "colab_type": "text"
      },
      "source": [
        "Saving model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFowGMHVbF6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "ce7a7c04-21e4-460d-bc59-afd4d021642d"
      },
      "source": [
        "import os\n",
        "\n",
        "output_dir = '/content/gdrive/My Drive/Amazon Seller Forum/bert_model/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to /content/gdrive/My Drive/Amazon Seller Forum/bert_model/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/gdrive/My Drive/Amazon Seller Forum/bert_model/vocab.txt',\n",
              " '/content/gdrive/My Drive/Amazon Seller Forum/bert_model/special_tokens_map.json',\n",
              " '/content/gdrive/My Drive/Amazon Seller Forum/bert_model/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIe6oDGWmWyy",
        "colab_type": "text"
      },
      "source": [
        "loading model for futre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3Qz9GyXmX1x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "dcf9c767-e38b-493d-a637-1ce4ab93fe8f"
      },
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "#model = ppb.BertForSequenceClassification.from_pretrained(output_dir)\n",
        "#tokenizer = ppb.DistilBertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "#model.to(device)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/gdrive/My Drive/Amazon Seller Forum/bert_model/ were not used when initializing BertForSequenceClassification: ['distilbert.embeddings.word_embeddings.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/gdrive/My Drive/Amazon Seller Forum/bert_model/ and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3THMeHz-qcJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}